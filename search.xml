<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Redis/SUMMARY</title>
      <link href="/2020/03/20/Redis/SUMMARY/"/>
      <url>/2020/03/20/Redis/SUMMARY/</url>
      
        <content type="html"><![CDATA[<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><ul><li><a href="README.md">Introduction</a></li><li>Redis基础<ul><li><a href="01-Redis介绍及NIO原理介绍.md">Redis介绍及NIO原理介绍</a></li><li><a href="02-Redis数据类型和使用场景.md">Redis数据类型和使用场景</a></li></ul></li><li>Redis使用进阶<ul><li><a href="03-Redis使用进阶.md">Redis使用进阶</a></li><li><a href="04-Redis持久化.md">Redis持久化</a></li></ul></li><li>Redis集群<ul><li><a href="05-Redis主从复制及高可用.md">Redis主从复制及高可用</a></li><li><a href="06-数据分片及Redis-Cluster.md">数据分片及Redis-Cluster</a></li></ul></li><li>Redis实战<ul><li><a href="07-Redis实战.md">Redis实战</a></li></ul></li><li>Zookeeper<ul><li><a href="08-初识zk.md">初识zk</a></li><li><a href="09-zk进阶.md">zk进阶</a></li></ul></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/README</title>
      <link href="/2020/03/20/Redis/README/"/>
      <url>/2020/03/20/Redis/README/</url>
      
        <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/09-zk进阶</title>
      <link href="/2020/03/20/Redis/09-zk%E8%BF%9B%E9%98%B6/"/>
      <url>/2020/03/20/Redis/09-zk%E8%BF%9B%E9%98%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="zk进阶"><a href="#zk进阶" class="headerlink" title="zk进阶"></a>zk进阶</h1><h2 id="paxos"><a href="#paxos" class="headerlink" title="paxos"></a>paxos</h2><p>​    <strong>基于消息传递的一致性算法</strong>，</p><h2 id="ZAB"><a href="#ZAB" class="headerlink" title="ZAB"></a>ZAB</h2><h2 id="watch"><a href="#watch" class="headerlink" title="watch"></a>watch</h2><h2 id="api-开发"><a href="#api-开发" class="headerlink" title="api 开发"></a>api 开发</h2><h2 id="callback"><a href="#callback" class="headerlink" title="callback"></a>callback</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/08-初识zk</title>
      <link href="/2020/03/20/Redis/08-%E5%88%9D%E8%AF%86zk/"/>
      <url>/2020/03/20/Redis/08-%E5%88%9D%E8%AF%86zk/</url>
      
        <content type="html"><![CDATA[<h1 id="初识zk"><a href="#初识zk" class="headerlink" title="初识zk"></a>初识zk</h1><h2 id="zk的特点"><a href="#zk的特点" class="headerlink" title="zk的特点"></a>zk的特点</h2><h2 id="zk基本使用"><a href="#zk基本使用" class="headerlink" title="zk基本使用"></a>zk基本使用</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/07-Redis实战</title>
      <link href="/2020/03/20/Redis/07-Redis%E5%AE%9E%E6%88%98/"/>
      <url>/2020/03/20/Redis/07-Redis%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis实战"><a href="#Redis实战" class="headerlink" title="Redis实战"></a>Redis实战</h1><h2 id="面试高频"><a href="#面试高频" class="headerlink" title="面试高频"></a>面试高频</h2><h3 id="击穿"><a href="#击穿" class="headerlink" title="击穿"></a>击穿</h3><p><img src="./pics/%E5%87%BB%E7%A9%BF.png" alt="击穿"></p><h3 id="雪崩"><a href="#雪崩" class="headerlink" title="雪崩"></a>雪崩</h3><p><img src="./pics/%E9%9B%AA%E5%B4%A9.jpg" alt="雪崩"></p><h3 id="穿透"><a href="#穿透" class="headerlink" title="穿透"></a>穿透</h3><p><img src="./pics/%E7%A9%BF%E9%80%8F.jpg" alt="穿透"></p><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><ul><li>用 redis 实现分布式锁的步骤<ul><li>setnx</li><li>设置锁过期时间，死锁变活锁</li><li>多线程（守护线程），延长过期时间</li></ul></li><li>redisson：redis java 客户端，实现了分布式锁 api</li><li>redis 实现分布式锁较复杂，zookeeper 当分布式锁更简单、更适合</li></ul><h2 id="开发实战"><a href="#开发实战" class="headerlink" title="开发实战"></a>开发实战</h2><h3 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h3><h3 id="high-low-API"><a href="#high-low-API" class="headerlink" title="high/low API"></a>high/low API</h3><h3 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h3><blockquote><p>见 <code>redis-demo</code> 项目代码</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/06-数据分片及Redis-Cluster</title>
      <link href="/2020/03/20/Redis/06-%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87%E5%8F%8ARedis-Cluster/"/>
      <url>/2020/03/20/Redis/06-%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87%E5%8F%8ARedis-Cluster/</url>
      
        <content type="html"><![CDATA[<h1 id="数据分片及Redis-Cluster"><a href="#数据分片及Redis-Cluster" class="headerlink" title="数据分片及Redis-Cluster"></a>数据分片及Redis-Cluster</h1><h2 id="技术推演"><a href="#技术推演" class="headerlink" title="技术推演"></a>技术推演</h2><p>​    一图胜千言，图片涵盖了整个推演过程，包括：</p><ol><li>为什么要进行 y 轴扩展及扩展方式：按业务、功能分库</li><li>y轴扩展仍存在压力问题的可能，因此需要z轴扩展，扩展思路是数据分片</li><li>数据分片方案一：客户端分区，存在问题：redis端连接成本高</li><li>为了解决方案一的问题，产生方案二：代理分区</li><li>方案一和二存在共同问题：不适合做数据库，否则增删节点很麻烦</li><li>问题的解决方案：预分区</li><li>数据分片方案三：查询路由，落地方案是Redis Cluster，实现了预分区，可做数据库</li></ol><p><img src="./pics/redis%E4%BB%A3%E7%90%86%E5%8F%8A%E9%9B%86%E7%BE%A4.jpg" alt="redis代理及集群"></p><h2 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h2><h3 id="twemproxy代理"><a href="#twemproxy代理" class="headerlink" title="twemproxy代理"></a>twemproxy代理</h3><p>​    twemproxy是一款被广泛使用的轻量级 Redis 和 Memcached 代理技术，相当于下图粉色部分。<a href="https://github.com/twitter/twemproxy/" target="_blank" rel="noopener">github主页</a></p><p><img src="./pics/redis-proxy.png" alt="redis-proxy"></p><h4 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h4><ol><li>下载、编译、配置、运行</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装编译需要的工具包</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum install -y automake libtool</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> wget https://github.com/twitter/twemproxy/archive/master.zip</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 编译</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> unzip master.zip</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> twemproxy-master</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> autoreconf -fvi</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ./configure --<span class="built_in">enable</span>-debug=full</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> make</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 看到正常的帮助信息，说明编译完成</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> src/nutcracker -h</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp src/nutcracker /usr/bin</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建 twemproxy 服务，根据 nutcracker.init 中的内容，将配置文件复制到指定目录下</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp scripts/nutcracker.init /etc/init.d/twemproxy</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> chmod +x /etc/init.d/twemproxy</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir -p /etc/nutcracker/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp conf/nutcracker.* /etc/nutcracker/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /etc/nutcracker/</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 备份一下配置文件</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp nutcracker.yml nutcracker.yml.bak</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vi nutcracker.yml</span></span><br></pre></td></tr></table></figure><p>​    <code>nutcracker.yml</code>中进行如下配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> alpha 一个名称，可随意起</span></span><br><span class="line">alpha:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 代理对外提供的服务地址</span></span><br><span class="line">  listen: 127.0.0.1:22121</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 哈希函数</span></span><br><span class="line">  hash: fnv1a_64</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 数据分片方式，支持ketama、modula、random</span></span><br><span class="line">  distribution: ketama</span><br><span class="line">  auto_eject_hosts: true</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 后端是否是 redis。默认为 <span class="literal">false</span>，代理 memcached</span></span><br><span class="line">  redis: true</span><br><span class="line">  server_retry_timeout: 2000</span><br><span class="line">  server_failure_limit: 1</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 后端服务的地址：权重</span></span><br><span class="line">  servers:</span><br><span class="line">   - 127.0.0.1:6379:1</span><br><span class="line">   - 127.0.0.1:6380:1</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 运行</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> TODO：自行在本机上运行两个 redis-server，端口分别是 6379 和 6380</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> service twemproxy start</span></span><br></pre></td></tr></table></figure><ol start="2"><li>测试效果</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 连接 tewmproxy 代理服务</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> redis-cli -p 22121</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">set</span> k1 a</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> get k1</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">set</span> k2 b</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">set</span> k3 c</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">set</span> 1 1</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> get 1</span></span><br></pre></td></tr></table></figure><blockquote><p><code>set</code>、<code>get</code>命令都能成功成功执行，说明代理正常提供服务</p><p>连接两个后端 redis，通过 <code>keys *</code>命令可以发现 k1、k2、k3落在一个节点上，1落在另一个节点上</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> twemproxy的局限性，聚合/事务 命令不再支持</span></span><br><span class="line">127.0.0.1:22121&gt; keys *</span><br><span class="line">Error: Server closed the connection</span><br><span class="line">127.0.0.1:22121&gt; WATCH k1</span><br><span class="line">Error: Server closed the connection</span><br><span class="line">127.0.0.1:22121&gt; MULTI</span><br><span class="line">Error: Server closed the connection</span><br></pre></td></tr></table></figure><h3 id="predixy代理"><a href="#predixy代理" class="headerlink" title="predixy代理"></a>predixy代理</h3><p>​    predixy是一款高性能全特征 redis 代理，支持 redis-sentinel 和 redis-cluster。比较小众，但是功能较强。<a href="https://github.com/joyieldInc/predixy/blob/master/README_CN.md" target="_blank" rel="noopener">github README</a></p><h4 id="实验步骤-1"><a href="#实验步骤-1" class="headerlink" title="实验步骤"></a>实验步骤</h4><ol><li>下载、配置</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> wget https://github.com/joyieldInc/predixy/releases/download/1.0.5/predixy-1.0.5-bin-amd64-linux.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> tar xf predixy-1.0.5-bin-amd64-linux.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> predixy-1.0.5/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> conf/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vi predixy.conf</span></span><br></pre></td></tr></table></figure><p>​    <code>predixy.conf</code>中修改两处：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">################################## GENERAL ####################################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Predixy configuration file example</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Specify a name for this predixy service</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># redis command INFO can get this</span></span></span><br><span class="line">Name PredixyExample</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Specify listen address, support IPV4, IPV6, Unix socket</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Examples:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 开启proxy监听端口</span></span><br><span class="line">Bind 127.0.0.1:7617</span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind 0.0.0.0:7617</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind /tmp/predixy</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Default is 0.0.0.0:7617</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind 0.0.0.0:7617</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">################################## SERVERS ####################################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Include cluster.conf</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动哨兵配置。目前 predixy 不支持同时开启 sentinel 和 redis-cluster</span></span><br><span class="line">Include sentinel.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> Include try.conf</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> vi sentinel.conf</span></span><br><span class="line">SentinelServerPool &#123;</span><br><span class="line">    Databases 16</span><br><span class="line">    Hash crc16</span><br><span class="line">    # 设置 hashtag 标记为“&#123;&#125;”，以后带有相同tag（如&#123;xx&#125;k1、&#123;xx&#125;k2）的key会落在同一个Redis节点上</span><br><span class="line">    HashTag "&#123;&#125;"</span><br><span class="line">    Distribution modula</span><br><span class="line">    MasterReadPriority 60</span><br><span class="line">    StaticSlaveReadPriority 50</span><br><span class="line">    DynamicSlaveReadPriority 50</span><br><span class="line">    RefreshInterval 1</span><br><span class="line">    ServerTimeout 1</span><br><span class="line">    ServerFailureLimit 10</span><br><span class="line">    ServerRetryTimeout 1</span><br><span class="line">    KeepAlive 120</span><br><span class="line">    Sentinels &#123;</span><br><span class="line">        # 配置 3 个哨兵</span><br><span class="line">        + 127.0.0.1:26379</span><br><span class="line">        + 127.0.0.1:26380</span><br><span class="line">        + 127.0.0.1:26381</span><br><span class="line">    &#125;</span><br><span class="line">    # 哨兵监控的master的逻辑名称，配置2个Group代表一套哨兵监控两套Redis主从</span><br><span class="line">    Group ooxx &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    Group xxoo &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>运行哨兵</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建3个哨兵的配置文件，分别是26379.conf，26380.conf和26381.conf</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 仅以 26379.conf 文件内容为例，其余两个文件内容仅端口号不同</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vi 26379.conf</span></span><br><span class="line">port 26379</span><br><span class="line">sentinel monitor ooxx 127.0.0.1 36379 2</span><br><span class="line">sentinel monitor xxoo 127.0.0.1 46379 2</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> redis-sentinel 26379.conf</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> redis-sentinel 26380.conf</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> redis-sentinel 26381.conf</span></span><br></pre></td></tr></table></figure><ol start="3"><li>运行 2 套 Redis 主从</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> redis-server -p 36379</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> redis-server  --port 36380 --replicaof 127.0.0.1 36379</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> redis-server -p 46379</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> redis-server  --port 46380 --replicaof 127.0.0.1 46379</span></span><br></pre></td></tr></table></figure><ol start="4"><li>运行predixy</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /opt/predixy-1.0.5/bin</span></span><br><span class="line">[root@localhost bin]# ./predixy ../conf/predixy.conf</span><br><span class="line">2020-02-03 17:56:45.214802 N Proxy.cpp:112 predixy listen in 127.0.0.1:7617</span><br><span class="line">2020-02-03 17:56:45.214952 N Proxy.cpp:143 predixy running with Name:PredixyExample Workers:1</span><br><span class="line">2020-02-03 17:56:45.215167 N Handler.cpp:454 h 0 create connection pool for server 127.0.0.1:26381</span><br><span class="line">2020-02-03 17:56:45.215226 N ConnectConnectionPool.cpp:42 h 0 create server connection 127.0.0.1:26381 5</span><br><span class="line">2020-02-03 17:56:45.253767 N Handler.cpp:454 h 0 create connection pool for server 127.0.0.1:26380</span><br><span class="line">2020-02-03 17:56:45.253826 N ConnectConnectionPool.cpp:42 h 0 create server connection 127.0.0.1:26380 6</span><br><span class="line">2020-02-03 17:56:45.254352 N StandaloneServerPool.cpp:422 sentinel server pool group xxoo create master server 127.0.0.1:46379</span><br><span class="line">2020-02-03 17:56:45.254366 N StandaloneServerPool.cpp:472 sentinel server pool group xxoo create slave server 127.0.0.1:46380</span><br><span class="line">2020-02-03 17:56:45.254384 N StandaloneServerPool.cpp:422 sentinel server pool group ooxx create master server 127.0.0.1:36379</span><br><span class="line">2020-02-03 17:56:45.254388 N StandaloneServerPool.cpp:472 sentinel server pool group ooxx create slave server 127.0.0.1:36380</span><br><span class="line">2020-02-03 17:56:46.263990 N Handler.cpp:454 h 0 create connection pool for server 127.0.0.1:26379</span><br><span class="line">2020-02-03 17:56:46.264082 N ConnectConnectionPool.cpp:42 h 0 create server connection 127.0.0.1:26379 7</span><br></pre></td></tr></table></figure><p>​    从 predixy 启动日志可以看出，已经找到了两套 master-slave</p><p><img src="./pics/%E5%AE%9E%E9%AA%8C%E6%9E%B6%E6%9E%84.png" alt="实验架构"></p><ol start="5"><li>测试效果</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 连接 predixy 代理服务</span></span><br><span class="line">[root@localhost ~]# redis-cli -p 7617</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span> 和 get 效果</span></span><br><span class="line">127.0.0.1:7617&gt; set k1 asd</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7617&gt; get k1</span><br><span class="line">"asd"</span><br><span class="line">127.0.0.1:7617&gt; set k2  ccc</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7617&gt; get k2</span><br><span class="line">"ccc"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> keys 命令也是不支持</span></span><br><span class="line">127.0.0.1:7617&gt; keys *</span><br><span class="line">(error) ERR unknown command 'keys'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置相同hashtag的keys</span></span><br><span class="line">127.0.0.1:7617&gt;  set &#123;oo&#125;k1 ccc</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7617&gt; set &#123;oo&#125;k2 zxzc</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7617&gt; get &#123;oo&#125;k1</span><br><span class="line">"ccc"</span><br><span class="line">127.0.0.1:7617&gt; get &#123;oo&#125;k2</span><br><span class="line">"zxzc"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 对于当前配置（配置了多组Redis后端），不支持事务</span></span><br><span class="line">127.0.0.1:7617&gt; WATCH &#123;oo&#125;k1</span><br><span class="line">(error) ERR forbid transaction in current server pool</span><br></pre></td></tr></table></figure><p>​    用客户端连接后端 redis，查看数据分布</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# redis-cli  -p 36379</span><br><span class="line">127.0.0.1:36379&gt; keys *</span><br><span class="line">1) "k1"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 相同hashtag的keys落在了一个Redis后端上</span></span><br><span class="line">[root@localhost ~]# redis-cli -p 46379</span><br><span class="line">127.0.0.1:46379&gt; keys *</span><br><span class="line">1) "&#123;oo&#125;k1"</span><br><span class="line">2) "k2"</span><br><span class="line">3) "&#123;oo&#125;k2"</span><br></pre></td></tr></table></figure><ol start="6"><li>关闭 predixy，修改 sentinel.conf 配置文件，去掉 <code>ooxx</code> Group后重启 predixy</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost bin]# vi ../conf/sentinel.conf</span><br><span class="line">SentinelServerPool &#123;</span><br><span class="line">    Databases 16</span><br><span class="line">    Hash crc16</span><br><span class="line">    HashTag "&#123;&#125;"</span><br><span class="line">    Distribution modula</span><br><span class="line">    MasterReadPriority 60</span><br><span class="line">    StaticSlaveReadPriority 50</span><br><span class="line">    DynamicSlaveReadPriority 50</span><br><span class="line">    RefreshInterval 1</span><br><span class="line">    ServerTimeout 1</span><br><span class="line">    ServerFailureLimit 10</span><br><span class="line">    ServerRetryTimeout 1</span><br><span class="line">    KeepAlive 120</span><br><span class="line">    Sentinels &#123;</span><br><span class="line">        + 127.0.0.1:26379</span><br><span class="line">        + 127.0.0.1:26380</span><br><span class="line">        + 127.0.0.1:26381</span><br><span class="line">    &#125;</span><br><span class="line">    # 哨兵监控的master的逻辑名称</span><br><span class="line">    Group xxoo &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@localhost bin]# ./predixy ../conf/predixy.conf</span><br></pre></td></tr></table></figure><ol start="7"><li>测试事务效果</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost sentinel]# redis-cli -p 7617</span><br><span class="line"><span class="meta">#</span><span class="bash"> 即使后端只有一组 Redis，也不支持 keys 命令</span></span><br><span class="line">127.0.0.1:7617&gt; keys *</span><br><span class="line">(error) ERR unknown command 'keys'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取不到k1，因为原来k1被放在了 ooxx 组里</span></span><br><span class="line">127.0.0.1:7617&gt; get k1</span><br><span class="line">(nil)</span><br><span class="line"><span class="meta">#</span><span class="bash"> 其它 xxoo 组里的数据仍能获取到</span></span><br><span class="line">127.0.0.1:7617&gt; get k2</span><br><span class="line">"ccc"</span><br><span class="line">127.0.0.1:7617&gt; get &#123;oo&#125;k1</span><br><span class="line">"ccc"</span><br><span class="line">127.0.0.1:7617&gt; get &#123;oo&#125;k2</span><br><span class="line">"zxzc"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 当只有一组 Redis 后端后，可以开启事务</span></span><br><span class="line">127.0.0.1:7617&gt; WATCH k1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7617&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7617&gt; set k1 newdata</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:7617&gt; EXEC</span><br><span class="line">1) OK</span><br><span class="line">127.0.0.1:7617&gt; get k1</span><br><span class="line">"newdata"</span><br></pre></td></tr></table></figure><ol start="8"><li><p>测试 sentinel 和备机</p><p>将 46379 服务停掉，观察现象可发现，在短暂的服务不可用（sentinel 正在将备机变成了新主节点）后，服务再次正常，数据仍在</p></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost sentinel]# redis-cli -p 7617</span><br><span class="line">127.0.0.1:7617&gt; get k1</span><br><span class="line">(error) ERR server connection close</span><br><span class="line">127.0.0.1:7617&gt; get k1</span><br><span class="line">"newdata"</span><br></pre></td></tr></table></figure><h3 id="Redis-Cluster"><a href="#Redis-Cluster" class="headerlink" title="Redis Cluster"></a>Redis Cluster</h3><p>​    Redis Cluster通过路由查询的方式实现数据分片。<a href="http://redis.cn/topics/cluster-tutorial.html" target="_blank" rel="noopener">Redis 集群初级教程</a></p><p><img src="./pics/Redis-Cluster.png" alt="Redis-Cluster"></p><h4 id="实验步骤-2"><a href="#实验步骤-2" class="headerlink" title="实验步骤"></a>实验步骤</h4><p>​    Redis 安装包里自带了一个 Redis cluster 的工具脚本，通过该脚本可以快速尝试 Redis Cluster</p><ol><li>启动</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost create-cluster]# cd /opt/redis-5.0.7/utils/create-cluster</span><br><span class="line">[root@localhost create-cluster]# ll</span><br><span class="line">总用量 8</span><br><span class="line">-rwxrwxr-x. 1 root root 2344 11月 20 01:05 create-cluster</span><br><span class="line">-rw-rw-r--. 1 root root 1317 11月 20 01:05 README</span><br><span class="line"><span class="meta">#</span><span class="bash"> 根据README中的步骤进行操作</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 先配置一下脚本中的部分参数</span></span><br><span class="line">[root@localhost create-cluster]# vi create-cluster</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Settings</span></span><br><span class="line">PORT=30000</span><br><span class="line">TIMEOUT=2000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动6个redis节点</span></span><br><span class="line">NODES=6</span><br><span class="line"><span class="meta">#</span><span class="bash"> 副本数设置为1，即6个节点，3份Redis，每份Redis是1主1从</span></span><br><span class="line">REPLICAS=1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 其他配置不变</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动Redis实例</span></span><br><span class="line">[root@localhost create-cluster]# ./create-cluster start</span><br><span class="line">Starting 30001</span><br><span class="line">Starting 30002</span><br><span class="line">Starting 30003</span><br><span class="line">Starting 30004</span><br><span class="line">Starting 30005</span><br><span class="line">Starting 30006</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建集群</span></span><br><span class="line">[root@localhost create-cluster]# ./create-cluster create</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing <span class="built_in">hash</span> slots allocation on 6 nodes...</span></span><br><span class="line">Master[0] -&gt; Slots 0 - 5460</span><br><span class="line">Master[1] -&gt; Slots 5461 - 10922</span><br><span class="line">Master[2] -&gt; Slots 10923 - 16383</span><br><span class="line">Adding replica 127.0.0.1:30005 to 127.0.0.1:30001</span><br><span class="line">Adding replica 127.0.0.1:30006 to 127.0.0.1:30002</span><br><span class="line">Adding replica 127.0.0.1:30004 to 127.0.0.1:30003</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Trying to optimize slaves allocation <span class="keyword">for</span> anti-affinity</span></span><br><span class="line">[WARNING] Some slaves are in the same host as their master</span><br><span class="line">M: 9eadfbf21e7b4589a7770a1ae7a64efcab8a2bca 127.0.0.1:30001</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">M: 4e8d6f113e37af7dba739c0167cf871087d1ae2e 127.0.0.1:30002</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">M: a31cfab0ca3d376f4ffd9ff7cde65f91be20fa7e 127.0.0.1:30003</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">S: ea8c01567da7ebcdeca71c5f61e04384dfc81a13 127.0.0.1:30004</span><br><span class="line">   replicates a31cfab0ca3d376f4ffd9ff7cde65f91be20fa7e</span><br><span class="line">S: 413b25c9a124c4be15310bd676c25a4566210828 127.0.0.1:30005</span><br><span class="line">   replicates 9eadfbf21e7b4589a7770a1ae7a64efcab8a2bca</span><br><span class="line">S: 0213aacf9991fc2d4f06a6e6ab891e24ea17778e 127.0.0.1:30006</span><br><span class="line">   replicates 4e8d6f113e37af7dba739c0167cf871087d1ae2e</span><br><span class="line">Can I set the above configuration? (type 'yes' to accept): yes</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Nodes configuration updated</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Assign a different config epoch to each node</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Sending CLUSTER MEET messages to join the cluster</span></span><br><span class="line">Waiting for the cluster to join</span><br><span class="line">.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing Cluster Check (using node 127.0.0.1:30001)</span></span><br><span class="line">M: 9eadfbf21e7b4589a7770a1ae7a64efcab8a2bca 127.0.0.1:30001</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 4e8d6f113e37af7dba739c0167cf871087d1ae2e 127.0.0.1:30002</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 0213aacf9991fc2d4f06a6e6ab891e24ea17778e 127.0.0.1:30006</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 4e8d6f113e37af7dba739c0167cf871087d1ae2e</span><br><span class="line">S: ea8c01567da7ebcdeca71c5f61e04384dfc81a13 127.0.0.1:30004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates a31cfab0ca3d376f4ffd9ff7cde65f91be20fa7e</span><br><span class="line">M: a31cfab0ca3d376f4ffd9ff7cde65f91be20fa7e 127.0.0.1:30003</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 413b25c9a124c4be15310bd676c25a4566210828 127.0.0.1:30005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 9eadfbf21e7b4589a7770a1ae7a64efcab8a2bca</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><p>​    在日志中可以看到 Redis 实例主从配对情况，及16384个槽位分配情况。</p><ol start="2"><li>测试效果</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 普通的 client 连接方式，命令会返回相应错误信息，告诉你应该把数据放到哪个 Redis 实例上</span></span><br><span class="line">[root@localhost create-cluster]# redis-cli -p 30001</span><br><span class="line">127.0.0.1:30001&gt; set k1 asd</span><br><span class="line">(error) MOVED 12706 127.0.0.1:30003</span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过 -c 参数指定为集群模式 client</span></span><br><span class="line">[root@localhost create-cluster]# redis-cli -p 30001 -c</span><br><span class="line">127.0.0.1:30001&gt; set k1 asd</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [12706] located at 127.0.0.1:30003</span></span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30003&gt; get k1</span><br><span class="line">"asd"</span><br><span class="line">127.0.0.1:30003&gt; set k2 czcx</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [449] located at 127.0.0.1:30001</span></span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30001&gt; set k3 weqw</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30003&gt; get k2</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [449] located at 127.0.0.1:30001</span></span><br><span class="line">"czcx"</span><br><span class="line">127.0.0.1:30001&gt; get k3</span><br><span class="line">"weqw"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 开启事务，没有报错</span></span><br><span class="line">127.0.0.1:30003&gt; WATCH k2</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [449] located at 127.0.0.1:30001</span></span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30001&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30001&gt; set k1 czx</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [12706] located at 127.0.0.1:30003</span></span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30003&gt; set ccc wedf</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [135] located at 127.0.0.1:30001</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta">#</span><span class="bash"> 提交事务时会出错，因为事务里操作了2个 Redis 实例上的数据，而MULTI 命令只提交给了30001，因此30003收到EXEC后会返回错误信息</span></span><br><span class="line">127.0.0.1:30001&gt; exec</span><br><span class="line">(error) ERR EXEC without MULTI</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置可是的hashtag，让事务操作的数据放到一个实例中，使事务正常使用</span></span><br><span class="line">127.0.0.1:30001&gt; set &#123;oo&#125;k1 aa</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30001&gt; set &#123;oo&#125;k2 zxc</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30001&gt; WATCH &#123;oo&#125;k1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30001&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30001&gt; get &#123;oo&#125;k3</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:30001&gt; set &#123;oo&#125;k2  newD</span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta">#</span><span class="bash"> 成功执行事务</span></span><br><span class="line">127.0.0.1:30001&gt; EXEC</span><br><span class="line">1) (nil)</span><br><span class="line">2) OK</span><br><span class="line">127.0.0.1:30001&gt; get &#123;oo&#125;k2</span><br><span class="line">"newD"</span><br></pre></td></tr></table></figure><ol start="3"><li>关闭实例并清空，换个玩法跑集群</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost create-cluster]# ./create-cluster stop</span><br><span class="line">Stopping 30001</span><br><span class="line">Stopping 30002</span><br><span class="line">Stopping 30003</span><br><span class="line">Stopping 30004</span><br><span class="line">Stopping 30005</span><br><span class="line">Stopping 30006</span><br><span class="line">[root@localhost create-cluster]# ./create-cluster clean</span><br><span class="line">[root@localhost create-cluster]# ll</span><br><span class="line">总用量 8</span><br><span class="line">-rwxrwxr-x. 1 root root 2344 11月 20 01:05 create-cluster</span><br><span class="line">-rw-rw-r--. 1 root root 1317 11月 20 01:05 README</span><br></pre></td></tr></table></figure><ol start="4"><li>通过脚本帮忙启动 6 个 Redis 实例，之后集群的操作由 client 命令完成</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost create-cluster]# ./create-cluster start</span><br><span class="line">Starting 30001</span><br><span class="line">Starting 30002</span><br><span class="line">Starting 30003</span><br><span class="line">Starting 30004</span><br><span class="line">Starting 30005</span><br><span class="line">Starting 30006</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看集群相关命令的说明文档</span></span><br><span class="line">[root@localhost create-cluster]# redis-cli --cluster help</span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过命令行创建集群，可以发现返回的日志和 ./create-cluster create 命令一样</span></span><br><span class="line">[root@localhost create-cluster]# redis-cli --cluster create 127.0.0.1:30001 127.0.0.1:30002 127.0.0.1:30003 127.0.0.1:30004 127.0.0.1:30005 127.0.0.1:30006 --cluster-replicas 1</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing <span class="built_in">hash</span> slots allocation on 6 nodes...</span></span><br><span class="line">Master[0] -&gt; Slots 0 - 5460</span><br><span class="line">Master[1] -&gt; Slots 5461 - 10922</span><br><span class="line">Master[2] -&gt; Slots 10923 - 16383</span><br><span class="line">Adding replica 127.0.0.1:30005 to 127.0.0.1:30001</span><br><span class="line">Adding replica 127.0.0.1:30006 to 127.0.0.1:30002</span><br><span class="line">Adding replica 127.0.0.1:30004 to 127.0.0.1:30003</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Trying to optimize slaves allocation <span class="keyword">for</span> anti-affinity</span></span><br><span class="line">[WARNING] Some slaves are in the same host as their master</span><br><span class="line">M: bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e 127.0.0.1:30001</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">M: d3cfdb22d35cd6e09a07824adff3af9a18e2c0ac 127.0.0.1:30002</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">M: 37e538350ef39dc7dd886325d71d4db0d6ae8c2a 127.0.0.1:30003</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">S: f190d2e34eaf62f7aa6efcd3ee20c419651169dd 127.0.0.1:30004</span><br><span class="line">   replicates 37e538350ef39dc7dd886325d71d4db0d6ae8c2a</span><br><span class="line">S: 10d004ac7557c113b94af0eb43df2da674d5fdc0 127.0.0.1:30005</span><br><span class="line">   replicates bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e</span><br><span class="line">S: ba905e12e22802e6e88884241d263eb4139fb354 127.0.0.1:30006</span><br><span class="line">   replicates d3cfdb22d35cd6e09a07824adff3af9a18e2c0ac</span><br><span class="line">Can I set the above configuration? (type 'yes' to accept): yes</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Nodes configuration updated</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Assign a different config epoch to each node</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Sending CLUSTER MEET messages to join the cluster</span></span><br><span class="line">Waiting for the cluster to join</span><br><span class="line">.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing Cluster Check (using node 127.0.0.1:30001)</span></span><br><span class="line">M: bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e 127.0.0.1:30001</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: d3cfdb22d35cd6e09a07824adff3af9a18e2c0ac 127.0.0.1:30002</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 37e538350ef39dc7dd886325d71d4db0d6ae8c2a 127.0.0.1:30003</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: ba905e12e22802e6e88884241d263eb4139fb354 127.0.0.1:30006</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates d3cfdb22d35cd6e09a07824adff3af9a18e2c0ac</span><br><span class="line">S: f190d2e34eaf62f7aa6efcd3ee20c419651169dd 127.0.0.1:30004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 37e538350ef39dc7dd886325d71d4db0d6ae8c2a</span><br><span class="line">S: 10d004ac7557c113b94af0eb43df2da674d5fdc0 127.0.0.1:30005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><ol start="5"><li>测试集群效果和集群相关 redis-cli 命令</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 测试是否正常使用</span></span><br><span class="line">[root@localhost create-cluster]# redis-cli  -c -p 30001</span><br><span class="line">127.0.0.1:30001&gt; get k1</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [12706] located at 127.0.0.1:30003</span></span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:30003&gt; set k1 asd</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:30003&gt; set k2 czx</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [449] located at 127.0.0.1:30001</span></span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 假设当前发生了数据倾斜，30001实例上数据太多，需要进行操作迁移</span></span><br><span class="line">[root@localhost create-cluster]# redis-cli --cluster reshard 127.0.0.1:30001</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing Cluster Check (using node 127.0.0.1:30001)</span></span><br><span class="line">M: bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e 127.0.0.1:30001</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: d3cfdb22d35cd6e09a07824adff3af9a18e2c0ac 127.0.0.1:30002</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 37e538350ef39dc7dd886325d71d4db0d6ae8c2a 127.0.0.1:30003</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: ba905e12e22802e6e88884241d263eb4139fb354 127.0.0.1:30006</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates d3cfdb22d35cd6e09a07824adff3af9a18e2c0ac</span><br><span class="line">S: f190d2e34eaf62f7aa6efcd3ee20c419651169dd 127.0.0.1:30004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 37e538350ef39dc7dd886325d71d4db0d6ae8c2a</span><br><span class="line">S: 10d004ac7557c113b94af0eb43df2da674d5fdc0 127.0.0.1:30005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line"><span class="meta">#</span><span class="bash"> 移动1000个槽位到其他实例</span></span><br><span class="line">How many slots do you want to move (from 1 to 16384)? 1000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 接收槽位的实例 ID</span></span><br><span class="line">What is the receiving node ID? d3cfdb22d35cd6e09a07824adff3af9a18e2c0ac</span><br><span class="line">Please enter all the source node IDs.</span><br><span class="line">  Type 'all' to use all the nodes as source nodes for the hash slots.</span><br><span class="line">  Type 'done' once you entered all the source nodes IDs.</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置只从30001上移走槽位</span></span><br><span class="line">Source node #1: bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e</span><br><span class="line">Source node #2: done</span><br><span class="line"></span><br><span class="line">Ready to move 1000 slots.</span><br><span class="line">  Source nodes:</span><br><span class="line">    M: bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e 127.0.0.1:30001</span><br><span class="line">       slots:[0-5460] (5461 slots) master</span><br><span class="line">       1 additional replica(s)</span><br><span class="line">  Destination node:</span><br><span class="line">    M: d3cfdb22d35cd6e09a07824adff3af9a18e2c0ac 127.0.0.1:30002</span><br><span class="line">       slots:[5461-10922] (5462 slots) master</span><br><span class="line">       1 additional replica(s)</span><br><span class="line">  Resharding plan:</span><br><span class="line">    Moving slot 0 from bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e</span><br><span class="line">    Moving slot 1 from bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e</span><br><span class="line">    Moving slot 2 from bfed58b1ec965e5b4d57edcdbd2ab92d2dc8e69e</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看30001槽位信息，可以发现30001中有1000个转到了30002</span></span><br><span class="line">[root@localhost create-cluster]# redis-cli --cluster info 127.0.0.1:30001</span><br><span class="line">127.0.0.1:30001 (bfed58b1...) -&gt; 0 keys | 4461 slots | 1 slaves.</span><br><span class="line">127.0.0.1:30002 (d3cfdb22...) -&gt; 1 keys | 6462 slots | 1 slaves.</span><br><span class="line">127.0.0.1:30003 (37e53835...) -&gt; 1 keys | 5461 slots | 1 slaves.</span><br><span class="line">[OK] 2 keys in 3 masters.</span><br><span class="line">0.00 keys per slot on average.</span><br><span class="line"><span class="meta">#</span><span class="bash"> check命令可以返回更详细的信息</span></span><br><span class="line">[root@localhost create-cluster]# redis-cli --cluster check 127.0.0.1:30001</span><br></pre></td></tr></table></figure><blockquote><p><code>redis-cli  -c -p 30001</code></p><p><code>redis-cli --cluster reshard 127.0.0.1:30001</code></p><p><code>redis-cli --cluster info 127.0.0.1:30001</code></p><p><code>redis-cli --cluster check 127.0.0.1:30001</code></p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/05-Redis主从复制及高可用</title>
      <link href="/2020/03/20/Redis/05-Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8F%8A%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
      <url>/2020/03/20/Redis/05-Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8F%8A%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis主从复制及高可用"><a href="#Redis主从复制及高可用" class="headerlink" title="Redis主从复制及高可用"></a>Redis主从复制及高可用</h1><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>​    一图胜千言，图片涵盖了整个推演过程，包括：</p><ol><li>单节点的问题，及问题的解决方案：一变多</li><li>一变多产生的新问题：数据一致性</li><li>数据一致性问题的三种解决方案</li><li>是什么主从、主备</li><li>主挂了怎么办？做主的HA高可用</li><li>主的高可用可以怎么做</li><li>监控程序的决策规则及数量分析</li></ol><p><img src="./pics/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8F%8A%E7%9B%91%E6%8E%A7.jpg" alt="主从复制及监控"></p><blockquote><p>在CAP定理中，单机 Redis 属于CP，Redis-Cluster 属于AP</p></blockquote><h2 id="Redis实战"><a href="#Redis实战" class="headerlink" title="Redis实战"></a>Redis实战</h2><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><p>​    Redis使用默认的异步复制的方式解决数据一致性问题，其特点是低延迟和高性能。</p><blockquote><p>即基本原理中提的方案二：弱一致性，容易数据丢失。</p><p>为什么没用方案三？因为Redis为了极高的性能而舍弃了数据完整性，加一个组件就多一步，多一步就慢一点</p></blockquote><p>基本命令：</p><p>​    <code>SLAVEOF host port</code>：Redis 5.0之前用的命令，自5.0起被废弃</p><p>​    <code>REPLICAOF host port</code>：自Redis 5.0开始<code>SLAVEOF</code>命令改成了<code>REPLICAOF</code>，用来让当前节点（未来的从）跟随另一个节点（未来的主）</p><h4 id="RDB的增量同步"><a href="#RDB的增量同步" class="headerlink" title="RDB的增量同步"></a>RDB的增量同步</h4><p>1️⃣ 对于没有开启 AOF 的两个 redis 服务，分别占用同一主机的 6379 和 6380 端口，让 6380 的 redis 通过 <code>REPLICAOF 127.0.0.1 3679</code>跟随 6379 主节点，主节点和从节点日志分别增加了如下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">5444:M 18 Jan 2020 11:04:13.108 * Replica 127.0.0.1:6380 asks for synchronization</span><br><span class="line">5444:M 18 Jan 2020 11:04:13.108 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for 'fbfc4bcee0568592ce7078f44d217c8eff096c22', my replication IDs are 'd6fb78d04bc9ed53662497dcf0c43050d291bf3d' and '0000000000000000000000000000000000000000')</span><br><span class="line">5444:M 18 Jan 2020 11:04:13.108 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">5444:M 18 Jan 2020 11:04:13.109 * Background saving started by pid 16176</span><br><span class="line">16176:C 18 Jan 2020 11:04:13.115 * DB saved on disk</span><br><span class="line">16176:C 18 Jan 2020 11:04:13.116 * RDB: 8 MB of memory used by copy-on-write</span><br><span class="line">5444:M 18 Jan 2020 11:04:13.213 * Background saving terminated with success</span><br><span class="line">5444:M 18 Jan 2020 11:04:13.214 * Synchronization with replica 127.0.0.1:6380 succeeded</span><br></pre></td></tr></table></figure><p>在主节点日志中可以看出：主节点生成了一个rdb文件，然后通过传递 rdb 内容实现从节点的数据同步</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">5893:S 18 Jan 2020 11:04:12.783 * Before turning into a replica, using my master parameters to synthesize a cached master: I may be able to synchronize with the new master with just a partial transfer.</span><br><span class="line">5893:S 18 Jan 2020 11:04:12.783 * REPLICAOF 127.0.0.1:6379 enabled (user request from 'id=4 addr=127.0.0.1:57102 fd=7 name= age=121 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=44 qbuf-free=32724 obl=0 oll=0 omem=0 events=r cmd=replicaof')</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.106 * Connecting to MASTER 127.0.0.1:6379</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.106 * MASTER &lt;-&gt; REPLICA sync started</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.106 * Non blocking connect for SYNC fired the event.</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.107 * Master replied to PING, replication can continue...</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.108 * Trying a partial resynchronization (request fbfc4bcee0568592ce7078f44d217c8eff096c22:1).</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.111 * Full resync from master: 99a12116a290d824730efeb03b741dfeaa40e914:0</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.112 * Discarding previously cached master state.</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.214 * MASTER &lt;-&gt; REPLICA sync: receiving 186 bytes from master</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.214 * MASTER &lt;-&gt; REPLICA sync: Flushing old data</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.214 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory</span><br><span class="line">5893:S 18 Jan 2020 11:04:13.214 * MASTER &lt;-&gt; REPLICA sync: Finished with success</span><br></pre></td></tr></table></figure><p>在从节点日志中可以看出：</p><ol><li>当前环境从节点同步数据时用的是 NIO，即不阻塞当前 redis 服务</li><li>先清空了本节点的当前数据，然后根据主节点传过来的数据进行恢复</li></ol><p>2️⃣ 此时将 6380 从节点挂掉，主节点日志多出一行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">5444:M 18 Jan 2020 11:26:36.102 # Connection with replica 127.0.0.1:6380 lost.</span><br></pre></td></tr></table></figure><p>3️⃣ 然后在 6379 中插入一条新数据后，将 6380 重新开起来，开启的时候需要直接追随<code>redis-server 6380.conf --replicaof 127.0.0.1 6379</code>，可以在主节点看到如下增加日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5444:M 18 Jan 2020 11:33:47.531 * Replica 127.0.0.1:6380 asks for synchronization</span><br><span class="line">5444:M 18 Jan 2020 11:33:47.532 * Partial resynchronization request from 127.0.0.1:6380 accepted. Sending 28 bytes of backlog starting from offset 2449.</span><br></pre></td></tr></table></figure><p>从日志可以看出，主节点知道 6380 之前连接过，在同步数据的时候，没有重新生成 rdb 文件进行全量同步，而是根据一个 offset 偏移量，算出两者间相差的数据，只传递相差的数据即可，即<font color='blue'>增量同步</font></p><blockquote><p>ps：一定要注意这是在没开启 AOF 情况下，即<code>appendonly no</code></p></blockquote><p>在 6380 从节点增加了以下日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">29400:S 18 Jan 2020 11:33:47.529 * Ready to accept connections</span><br><span class="line">29400:S 18 Jan 2020 11:33:47.529 * Connecting to MASTER 127.0.0.1:6379</span><br><span class="line">29400:S 18 Jan 2020 11:33:47.529 * MASTER &lt;-&gt; REPLICA sync started</span><br><span class="line">29400:S 18 Jan 2020 11:33:47.530 * Non blocking connect for SYNC fired the event.</span><br><span class="line">29400:S 18 Jan 2020 11:33:47.530 * Master replied to PING, replication can continue...</span><br><span class="line">29400:S 18 Jan 2020 11:33:47.531 * Trying a partial resynchronization (request 99a12116a290d824730efeb03b741dfeaa40e914:2449).</span><br><span class="line">29400:S 18 Jan 2020 11:33:47.532 * Successful partial resynchronization with master.</span><br><span class="line">29400:S 18 Jan 2020 11:33:47.533 * MASTER &lt;-&gt; REPLICA sync: Master accepted a Partial Resynchronization.</span><br></pre></td></tr></table></figure><p>在从节点日志中也可以看出，只进行了 “partial resynchronization”</p><p>查看 6380 的dump.rbd 文件，会发现里面记录了<code>repl-id</code>信息</p><p><img src="./pics/dump.jpg" alt="dump"></p><h4 id="AOF的全量同步"><a href="#AOF的全量同步" class="headerlink" title="AOF的全量同步"></a>AOF的全量同步</h4><p>​    在 redis 节点都开启 AOF 情况下，同样进行以上步骤，观察日志</p><p>1️⃣ 从节点跟随主节点后，主节点增加了以下日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">10558:M 18 Jan 2020 12:05:11.388 * Replica 127.0.0.1:6380 asks for synchronization</span><br><span class="line">10558:M 18 Jan 2020 12:05:11.388 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for '737245cf673a3e365055205db9da4523e8f4835d', my replication IDs are 'b0745e23caa0e81833246a51b3ba02b14865fdce' and '0000000000000000000000000000000000000000')</span><br><span class="line">10558:M 18 Jan 2020 12:05:11.388 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">10558:M 18 Jan 2020 12:05:11.390 * Background saving started by pid 11526</span><br><span class="line">11526:C 18 Jan 2020 12:05:11.399 * DB saved on disk</span><br><span class="line">11526:C 18 Jan 2020 12:05:11.400 * RDB: 6 MB of memory used by copy-on-write</span><br><span class="line">10558:M 18 Jan 2020 12:05:11.420 * Background saving terminated with success</span><br><span class="line">10558:M 18 Jan 2020 12:05:11.420 * Synchronization with replica 127.0.0.1:6380 succeeded</span><br><span class="line">10558:M 18 Jan 2020 12:05:20.247 * Replica 127.0.0.1:6390 asks for synchronization</span><br></pre></td></tr></table></figure><p>可以看出虽然主节点开启了 AOF，但是在第一次同步的时候，仍然生成了 rdb 文件并传输给从节点。查看日志文件</p><p>从节点日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">10614:S 18 Jan 2020 12:05:10.545 * Before turning into a replica, using my master parameters to synthesize a cached master: I may be able to synchronize with the new master with just a partial transfer.</span><br><span class="line">10614:S 18 Jan 2020 12:05:10.545 * REPLICAOF 127.0.0.1:6379 enabled (user request from 'id=3 addr=127.0.0.1:43512 fd=8 name= age=29 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=44 qbuf-free=32724 obl=0 oll=0 omem=0 events=r cmd=replicaof')</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.386 * Connecting to MASTER 127.0.0.1:6379</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.386 * MASTER &lt;-&gt; REPLICA sync started</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.386 * Non blocking connect for SYNC fired the event.</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.386 * Master replied to PING, replication can continue...</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.387 * Trying a partial resynchronization (request 737245cf673a3e365055205db9da4523e8f4835d:1).</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.392 * Full resync from master: 2f3ca94abbb48eae4192d5819a2f8011d79a8210:0</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.392 * Discarding previously cached master state.</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.420 * MASTER &lt;-&gt; REPLICA sync: receiving 188 bytes from master</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.420 * MASTER &lt;-&gt; REPLICA sync: Flushing old data</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.422 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.422 * MASTER &lt;-&gt; REPLICA sync: Finished with success</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.425 * Background append only file rewriting started by pid 11527</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.488 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">11527:C 18 Jan 2020 12:05:11.488 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">11527:C 18 Jan 2020 12:05:11.488 * Concatenating 0.00 MB of AOF diff received from parent.</span><br><span class="line">11527:C 18 Jan 2020 12:05:11.490 * SYNC append only file rewrite performed</span><br><span class="line">11527:C 18 Jan 2020 12:05:11.491 * AOF rewrite: 4 MB of memory used by copy-on-write</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.597 * Background AOF rewrite terminated with success</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.597 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">10614:S 18 Jan 2020 12:05:11.597 * Background AOF rewrite finished successfully</span><br></pre></td></tr></table></figure><p>2️⃣ 挂掉 6380 从节点，在主节点中插入一条日志后</p><p>3️⃣ 恢复 6380 从节点<code>redis-server 6380.conf --replicaof 127.0.0.1 6379</code>，查看主节点日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">10558:M 18 Jan 2020 13:06:58.958 * Replica 127.0.0.1:6380 asks for synchronization</span><br><span class="line">10558:M 18 Jan 2020 13:06:58.958 * Full resync requested by replica 127.0.0.1:6380</span><br><span class="line">10558:M 18 Jan 2020 13:06:58.958 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">10558:M 18 Jan 2020 13:06:58.960 * Background saving started by pid 5988</span><br><span class="line">5988:C 18 Jan 2020 13:06:59.131 * DB saved on disk</span><br><span class="line">5988:C 18 Jan 2020 13:06:59.133 * RDB: 4 MB of memory used by copy-on-write</span><br><span class="line">10558:M 18 Jan 2020 13:06:59.144 * Background saving terminated with success</span><br><span class="line">10558:M 18 Jan 2020 13:06:59.144 * Synchronization with replica 127.0.0.1:6380 succeeded</span><br></pre></td></tr></table></figure><p>可以看出主节点还是生成了一个 rdb 文件传给从节点。</p><p>查看从节点日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">5984:S 18 Jan 2020 13:06:58.957 * Connecting to MASTER 127.0.0.1:6379</span><br><span class="line">5984:S 18 Jan 2020 13:06:58.957 * MASTER &lt;-&gt; REPLICA sync started</span><br><span class="line">5984:S 18 Jan 2020 13:06:58.957 * Non blocking connect for SYNC fired the event.</span><br><span class="line">5984:S 18 Jan 2020 13:06:58.958 * Master replied to PING, replication can continue...</span><br><span class="line">5984:S 18 Jan 2020 13:06:58.958 * Partial resynchronization not possible (no cached master)</span><br><span class="line">5984:S 18 Jan 2020 13:06:58.961 * Full resync from master: 2f3ca94abbb48eae4192d5819a2f8011d79a8210:5387</span><br><span class="line">5984:S 18 Jan 2020 13:06:59.144 * MASTER &lt;-&gt; REPLICA sync: receiving 308 bytes from master</span><br><span class="line">5984:S 18 Jan 2020 13:06:59.144 * MASTER &lt;-&gt; REPLICA sync: Flushing old data</span><br><span class="line">5984:S 18 Jan 2020 13:06:59.145 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory</span><br><span class="line">5984:S 18 Jan 2020 13:06:59.145 * MASTER &lt;-&gt; REPLICA sync: Finished with success</span><br><span class="line">5984:S 18 Jan 2020 13:06:59.147 * Background append only file rewriting started by pid 5989</span><br><span class="line">5984:S 18 Jan 2020 13:06:59.193 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">5989:C 18 Jan 2020 13:06:59.193 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">5989:C 18 Jan 2020 13:06:59.193 * Concatenating 0.00 MB of AOF diff received from parent.</span><br><span class="line">5989:C 18 Jan 2020 13:06:59.194 * SYNC append only file rewrite performed</span><br><span class="line">5989:C 18 Jan 2020 13:06:59.195 * AOF rewrite: 4 MB of memory used by copy-on-write</span><br><span class="line">5984:S 18 Jan 2020 13:06:59.272 * Background AOF rewrite terminated with success</span><br><span class="line">5984:S 18 Jan 2020 13:06:59.273 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">5984:S 18 Jan 2020 13:06:59.273 * Background AOF rewrite finished successfully</span><br></pre></td></tr></table></figure><p>在从节点日志中可以发现，开启 AOF 后，增量更新前置条件判断失败了 “Partial resynchronization not possible (no cached master)”，因此通过 rdb 文件进行了<font color='blue'>全量同步</font>。在数据同步成功后，进行了一次 AOF 持久化。</p><p>查看 6380 的日志文件目录，可以观察到目录下多了两个日志文件，包括从主节点获取到的 rdb 和自己生成的 aof</p><blockquote><p>为什么开启 AOF 后，数据变成了全量同步？</p><p>具体情况不清楚，不知道是 redis 的 bug 还是故意这么设计的</p></blockquote><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>​    关于主从复制，在 redis 配置文件中有以下关键的可配置项</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> replicaof &lt;masterip&gt; &lt;masterport&gt;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> masterauth &lt;master-password&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 从节点在获取主节点数据，即 rdb 文件时，是否对外提供服务，默认是 yes，代表继续对外提供服务</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 当置为 no 时，客户端的请求都会返回<span class="string">"SYNC with master in progress"</span></span></span><br><span class="line">replica-serve-stale-data yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置从节点是否只提供读功能</span></span><br><span class="line">replica-read-only yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进行从节点同步的时候，有两种方式： disk 和 socket</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 一种是在磁盘中生成 rdb 文件然后传递给从节点</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 另一种是一边在内存中生成 rdb 数据，一边直接把数据通过 socket 传给从节点</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认是使用 disk 方式，在 redis 5.0.7版本，socket 方式还处于实验阶段</span></span><br><span class="line">repl-diskless-sync no</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在内存中有一块叫做 backlog 的buffer，该参数是设置该 buffer 大小的</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这个buffer作用是什么？当一个从节点挂掉后，主节点发生了写操作，这时就把这些数据存到buffer中作为副本。当从节点恢复后，直接将buffer里的副本数据传给从节点实现数据同步，不再需要全量同步数据</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果在从节点宕机期间，主节点操作的数据量超过了buffer大小，那么从节点重启后就会进行全量同步</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这个buffer只有在有从节点时才会存在</span></span><br><span class="line">repl-backlog-size 1mb</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 以下两个配置代表：至少存在3个replica连接master的延迟时间小于10秒时，主节点才允许进行写操作</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> min-replicas-to-write 3 <span class="comment"># 默认是是 0</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> min-replicas-max-lag 10</span></span><br></pre></td></tr></table></figure><h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>​    当主节点挂掉后，我们要把某个从节点置为新的主节点，并让其它从节点跟随新的主节点</p><h4 id="手动方式"><a href="#手动方式" class="headerlink" title="手动方式"></a>手动方式</h4><p>​    通过执行<code>REPLICAOF no one</code>命令，可以让原本的一个从节点变成主节点，日志如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">3523:S 18 Jan 2020 14:19:19.522 * Connecting to MASTER 127.0.0.1:6379</span><br><span class="line">3523:S 18 Jan 2020 14:19:19.523 * MASTER &lt;-&gt; REPLICA sync started</span><br><span class="line">3523:S 18 Jan 2020 14:19:19.523 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">3523:M 18 Jan 2020 14:19:20.107 # Setting secondary replication ID to 1873effbe3b674cbb1b3014675ed387feb7ca247, valid up to offset: 15. New replication ID is 82819ad6416ce85c0b01130a15c2d85f4615b738</span><br><span class="line">3523:M 18 Jan 2020 14:19:20.107 * Discarding previously cached master state.</span><br><span class="line">3523:M 18 Jan 2020 14:19:20.107 * MASTER MODE enabled (user request from 'id=4 addr=127.0.0.1:45174 fd=7 name= age=259 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=36 qbuf-free=32732 obl=0 oll=0 omem=0 events=r cmd=replicaof')</span><br></pre></td></tr></table></figure><p>​    一开始这个节点还在找原来的主节点，执行命令后，自己就变成了主节点</p><p>​    其它从节点是不知道有一个从节点变成主节点这件事的，它们还在找挂掉的主节点。其它从节点需要通过命令<code>REPLICAOF 127.0.0.1 6380</code>设置新的追随节点</p><h4 id="自动方式"><a href="#自动方式" class="headerlink" title="自动方式"></a>自动方式</h4><p>1️⃣ 先启动三个 redis 实例，在同一台主机上用不同端口区分，6379 6380 和 6390。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">redis-server 6379.conf</span><br><span class="line"></span><br><span class="line">redis-server 6380.conf --replicaof 127.0.0.1 6379</span><br><span class="line"></span><br><span class="line">redis-server 6390.conf --replicaof 127.0.0.1 6379</span><br></pre></td></tr></table></figure><p>2️⃣ 创建三个 sentinel 的配置文件，文件内容类似，区别在于端口不同，文件内容如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> sentinel程序端口</span></span><br><span class="line">port 26379</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置监听的主节点信息，最后一个 <span class="string">"2"</span> 代表达到多少个势力范围就可以做出结论</span></span><br><span class="line">sentinel monitor mymaster 127.0.0.1 6379 2</span><br></pre></td></tr></table></figure><p>3️⃣ 开启三个 sentinel，通过以下两个命令中的任意一个均可开启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-sentinel /tmp/redis-configs/26379.conf</span><br><span class="line">redis-server /tmp/redis-configs/26380.conf --sentinel</span><br></pre></td></tr></table></figure><p>观察打印日志，前面四行可以看出，监控主节点后，监控程序可以直接找到从节点的位置信息。</p><p>最后两行说明当其他 sentinel 创建后，当前 sentinel 可以立刻发现它们，最终实现 3 个sentinel 组成为一个监控集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">31958:X 18 Jan 2020 15:20:19.093 # Sentinel ID is bb8212924cbeaa1bd85b40329e7dc4105d3207e8</span><br><span class="line">31958:X 18 Jan 2020 15:20:19.093 # +monitor master mymaster 127.0.0.1 6379 quorum 2</span><br><span class="line">31958:X 18 Jan 2020 15:20:19.094 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:20:19.107 * +slave slave 127.0.0.1:6390 127.0.0.1 6390 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:21:26.460 * +sentinel sentinel 8eea978d886a97420a88680950783acb63c489fc 127.0.0.1 26380 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:24:00.228 * +sentinel sentinel a1fef01748b6dcd923ba04226cd7f868facf37c9 127.0.0.1 26390 @ mymaster 127.0.0.1 6379</span><br></pre></td></tr></table></figure><blockquote><p>sentinel 在监控主节点后，获取从节点信息是很容易理解的，因为本身主节点里就会有从节点的信息。</p><p>但是 sentinel 是如何发现其他 sentinel，使大家成为一个监控集群的呢？</p><p>是通过 redis 的pubsub功能实现的。sentinel 在 redis 主节点上开启一个发布订阅，所有 sentinel 都订阅这个频道，就可以实现互相间的感知和通讯了。通过<code>SUBSCRIBE __sentinel__:hello</code>可以看到 sentinel 之间的通信</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6390&gt; SUBSCRIBE __sentinel__:hello</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">1) "subscribe"</span><br><span class="line">2) "__sentinel__:hello"</span><br><span class="line">3) (integer) 1</span><br><span class="line">1) "message"</span><br><span class="line">2) "__sentinel__:hello"</span><br><span class="line">3) "127.0.0.1,26390,a1fef01748b6dcd923ba04226cd7f868facf37c9,1,mymaster,127.0.0.1,6380,1"</span><br><span class="line">1) "message"</span><br><span class="line">2) "__sentinel__:hello"</span><br><span class="line">3) "127.0.0.1,26380,8eea978d886a97420a88680950783acb63c489fc,1,mymaster,127.0.0.1,6380,1"</span><br><span class="line">1) "message"</span><br><span class="line">2) "__sentinel__:hello"</span><br><span class="line">3) "127.0.0.1,26390,a1fef01748b6dcd923ba04226cd7f868facf37c9,1,mymaster,127.0.0.1,6380,1"</span><br><span class="line">1) "message"</span><br><span class="line">2) "__sentinel__:hello"</span><br><span class="line">3) "127.0.0.1,26379,bb8212924cbeaa1bd85b40329e7dc4105d3207e8,1,mymaster,127.0.0.1,6380,1"</span><br><span class="line">1) "message"</span><br></pre></td></tr></table></figure></blockquote><p>4️⃣ 此时把 redis 主节点停掉，观察从节点日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">10549:S 18 Jan 2020 15:30:41.249 * Connecting to MASTER 127.0.0.1:6379</span><br><span class="line">10549:S 18 Jan 2020 15:30:41.249 * MASTER &lt;-&gt; REPLICA sync started</span><br><span class="line">10549:S 18 Jan 2020 15:30:41.249 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">10549:M 18 Jan 2020 15:30:41.250 # Setting secondary replication ID to acf90cf8130bc3e3159a2408272994e8f629f3a8, valid up to offset: 102058. New replication ID is 39d3efdce306ee509a3df53e4fd95dd930d2fb8f</span><br><span class="line">10549:M 18 Jan 2020 15:30:41.250 * Discarding previously cached master state.</span><br><span class="line">10549:M 18 Jan 2020 15:30:41.250 * MASTER MODE enabled (user request from 'id=4 addr=127.0.0.1:60158 fd=7 name=sentinel-bb821292-cmd age=622 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=140 qbuf-free=32628 obl=36 oll=0 omem=0 events=r cmd=exec')</span><br><span class="line">10549:M 18 Jan 2020 15:30:41.253 # CONFIG REWRITE executed with success.</span><br><span class="line">10549:M 18 Jan 2020 15:30:42.163 * Replica 127.0.0.1:6390 asks for synchronization</span><br><span class="line">10549:M 18 Jan 2020 15:30:42.164 * Partial resynchronization request from 127.0.0.1:6390 accepted. Sending 422 bytes of backlog starting from offset 102058.</span><br></pre></td></tr></table></figure><p>可以看到，在出现短暂无主后，6380 节点被选成了新的主节点</p><p>查看 6390 的日志，发现它重新追随了 6380 节点，并与新的主节点进行了一次数据同步</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">10581:S 18 Jan 2020 15:30:41.143 * Connecting to MASTER 127.0.0.1:6379</span><br><span class="line">10581:S 18 Jan 2020 15:30:41.144 * MASTER &lt;-&gt; REPLICA sync started</span><br><span class="line">10581:S 18 Jan 2020 15:30:41.144 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">10581:S 18 Jan 2020 15:30:41.952 * REPLICAOF 127.0.0.1:6380 enabled (user request from 'id=4 addr=127.0.0.1:35456 fd=7 name=sentinel-bb821292-cmd age=622 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=281 qbuf-free=32487 obl=36 oll=0 omem=0 events=r cmd=exec')</span><br><span class="line">10581:S 18 Jan 2020 15:30:41.956 # CONFIG REWRITE executed with success.</span><br><span class="line">10581:S 18 Jan 2020 15:30:42.162 * Connecting to MASTER 127.0.0.1:6380</span><br><span class="line">10581:S 18 Jan 2020 15:30:42.162 * MASTER &lt;-&gt; REPLICA sync started</span><br><span class="line">10581:S 18 Jan 2020 15:30:42.162 * Non blocking connect for SYNC fired the event.</span><br><span class="line">10581:S 18 Jan 2020 15:30:42.163 * Master replied to PING, replication can continue...</span><br><span class="line">10581:S 18 Jan 2020 15:30:42.163 * Trying a partial resynchronization (request acf90cf8130bc3e3159a2408272994e8f629f3a8:102058).</span><br><span class="line">10581:S 18 Jan 2020 15:30:42.164 * Successful partial resynchronization with master.</span><br><span class="line">10581:S 18 Jan 2020 15:30:42.164 # Master replication ID changed to 39d3efdce306ee509a3df53e4fd95dd930d2fb8f</span><br><span class="line">10581:S 18 Jan 2020 15:30:42.164 * MASTER &lt;-&gt; REPLICA sync: Master accepted a Partial Resynchronization.</span><br></pre></td></tr></table></figure><p>查看 sentinel 日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">31958:X 18 Jan 2020 15:30:40.803 # +sdown master mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:40.884 # +odown master mymaster 127.0.0.1 6379 #quorum 2/2</span><br><span class="line">31958:X 18 Jan 2020 15:30:40.884 # +new-epoch 1</span><br><span class="line">31958:X 18 Jan 2020 15:30:40.884 # +try-failover master mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.067 # +vote-for-leader bb8212924cbeaa1bd85b40329e7dc4105d3207e8 1</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.070 # a1fef01748b6dcd923ba04226cd7f868facf37c9 voted for a1fef01748b6dcd923ba04226cd7f868facf37c9 1</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.078 # 8eea978d886a97420a88680950783acb63c489fc voted for bb8212924cbeaa1bd85b40329e7dc4105d3207e8 1</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.120 # +elected-leader master mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.120 # +failover-state-select-slave master mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.178 # +selected-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.178 * +failover-state-send-slaveof-noone slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.249 * +failover-state-wait-promotion slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.855 # +promoted-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.855 # +failover-state-reconf-slaves master mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:41.952 * +slave-reconf-sent slave 127.0.0.1:6390 127.0.0.1 6390 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:42.157 # -odown master mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:42.860 * +slave-reconf-inprog slave 127.0.0.1:6390 127.0.0.1 6390 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:42.860 * +slave-reconf-done slave 127.0.0.1:6390 127.0.0.1 6390 @ mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:42.951 # +failover-end master mymaster 127.0.0.1 6379</span><br><span class="line">31958:X 18 Jan 2020 15:30:42.951 # +switch-master mymaster 127.0.0.1 6379 127.0.0.1 6380</span><br><span class="line">31958:X 18 Jan 2020 15:30:42.952 * +slave slave 127.0.0.1:6390 127.0.0.1 6390 @ mymaster 127.0.0.1 6380</span><br><span class="line">31958:X 18 Jan 2020 15:30:42.952 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6380</span><br><span class="line">31958:X 18 Jan 2020 15:31:13.015 # +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6380</span><br></pre></td></tr></table></figure><p>满足 2 票主节点为宕机后，三个 sentinel 进行了投票，最终选出新的主节点为 6380，实现自动化的高可用</p><h4 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h4><p>​    sentinel 的配置文件在 redis 源码目录下存在，文件名是<code>sentinel.conf</code>。配置文件内容和 redis 的配置文件很像，关键的配置如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">port 26379</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> quorum，当达到quorum个数势力范围时，可以给出结论。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> quorum 根据是否允许分区容错性来定，再不允许的场景下常是 （总监控个数/2 + 1）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/04-Redis持久化</title>
      <link href="/2020/03/20/Redis/04-Redis%E6%8C%81%E4%B9%85%E5%8C%96/"/>
      <url>/2020/03/20/Redis/04-Redis%E6%8C%81%E4%B9%85%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a>Redis持久化</h1><h2 id="什么时候需要持久化"><a href="#什么时候需要持久化" class="headerlink" title="什么时候需要持久化"></a>什么时候需要持久化</h2><p>​    当 redis 作为缓存时，性能极高，数据可以丢</p><p>​    当 redis 作为数据库时，性能较高，数据绝对不能丢。因为 redis 是内存数据库，因此<font color='red'>掉电易失</font>，所以这种场景下，必需有数据持久化的解决方案</p><h2 id="单机持久化"><a href="#单机持久化" class="headerlink" title="单机持久化"></a>单机持久化</h2><h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3><p>​    rdb 相当于周期性的对内存数据进行一次快照，快照内容是二进制数据，将快照作为以后的恢复文件。</p><h4 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h4><p><img src="./pics/RDB.jpg" alt="RDB"></p><h4 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h4><p>​    客户端可以通过命令触发 rdb </p><ul><li><p><code>SAVE</code>：同步保存，使用场景明确，如：关机维护</p></li><li><p><code>BGSAVE</code>：异步方式进行保存，通过 fork 创建子进程方式实现</p><p>对于 rdb 文件，一定是以”REDIS”开头，后面是二进制内容。通过命令行工具可以检查 rdb 文件内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@node162 6380]# redis-check-rdb dump.rdb</span><br><span class="line">[offset 0] Checking RDB file dump.rdb</span><br><span class="line">[offset 26] AUX FIELD redis-ver = '5.0.7'</span><br><span class="line">[offset 40] AUX FIELD redis-bits = '64'</span><br><span class="line">[offset 52] AUX FIELD ctime = '1579335183'</span><br><span class="line">[offset 67] AUX FIELD used-mem = '2028456'</span><br><span class="line">[offset 85] AUX FIELD repl-stream-db = '0'</span><br><span class="line">[offset 135] AUX FIELD repl-id = '39d3efdce306ee509a3df53e4fd95dd930d2fb8f'</span><br><span class="line">[offset 153] AUX FIELD repl-offset = '603016'</span><br><span class="line">[offset 169] AUX FIELD aof-preamble = '0'</span><br><span class="line">[offset 171] Selecting DB ID 0</span><br><span class="line">[offset 206] Checksum OK</span><br><span class="line">[offset 206] \o/ RDB looks OK! \o/</span><br><span class="line">[info] 3 keys read</span><br><span class="line">[info] 0 expires</span><br><span class="line">[info] 0 already expired</span><br></pre></td></tr></table></figure></li></ul><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 除了命令行触发rdb，在配置文件中也可以写触发规则，这种触发的是异步保存方式</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> save <span class="string">""</span> 代表关闭 rdb</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 900内触发1次写，就发生 rdb</span></span><br><span class="line">save 900 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 300内触发10次写，就发生 rdb</span></span><br><span class="line">save 300 10</span><br><span class="line"><span class="meta">#</span><span class="bash"> 60内触发10000次写，就发生 rdb</span></span><br><span class="line">save 60 10000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 是否压缩</span></span><br><span class="line">rdbcompression yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件末尾是否生成 checksum 校验</span></span><br><span class="line">rdbchecksum yes</span><br><span class="line"></span><br><span class="line">dbfilename "dump.rdb"</span><br><span class="line">dir "/var/lib/redis/6379"</span><br></pre></td></tr></table></figure><h4 id="触发RDB的时机"><a href="#触发RDB的时机" class="headerlink" title="触发RDB的时机"></a>触发RDB的时机</h4><ol><li><code>shutdown</code>时，如果没开启aof，则会触发rdb</li><li>满足了配置文件中<code>save</code>的配置时机</li><li>命令行触发<code>save</code>或者<code>bgsave</code>时</li><li>命令行触发<code>flushall</code>命令时，也会生成一个空的<code>dump.rdb</code>文件</li></ol><h4 id="fork-底层原理"><a href="#fork-底层原理" class="headerlink" title="fork 底层原理"></a>fork 底层原理</h4><p><img src="./pics/fork%E5%8E%9F%E7%90%86.jpg" alt="fork原理"></p><blockquote><p>证明：linux 中管道符 “|” 会触发创建【子进程】</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="string">"$$"</span> 打印当前 shell 进程号</span></span><br><span class="line">[root@localhost data]# echo $$</span><br><span class="line">10169</span><br><span class="line"><span class="meta">#</span><span class="bash"> 为什么下面一条命令打印的进程号和父进程号一样？</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> $$ 优先级高于 |，因此执行管道符之前 $$ 已经被替换了</span></span><br><span class="line">[root@localhost data]# echo $$ | more</span><br><span class="line">10169</span><br><span class="line"><span class="meta">#</span><span class="bash"> 下面一条命令证明了：管道符两边的命令会创建子进程</span></span><br><span class="line">[root@localhost data]# echo $BASHPID | more</span><br><span class="line"><span class="meta">#</span><span class="bash"> 子进程号和父进程号不一样</span></span><br><span class="line">17617</span><br></pre></td></tr></table></figure></blockquote><blockquote><p>证明：父进程的数据默认不对子进程可见，通过 export 可以使变量对子进程可见</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在父 shell 里创建变量<span class="string">"a"</span></span></span><br><span class="line">[root@localhost data]# a=10</span><br><span class="line">[root@localhost data]# echo $a</span><br><span class="line">10</span><br><span class="line">[root@localhost data]# echo $$</span><br><span class="line">10169</span><br><span class="line"><span class="meta">#</span><span class="bash"> 新开一个 bash，创建子进程</span></span><br><span class="line">[root@localhost data]# /bin/bash</span><br><span class="line">[root@localhost data]# echo $$</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进程号已改变</span></span><br><span class="line">17653</span><br><span class="line"><span class="meta">#</span><span class="bash"> 子进程获取不到变量<span class="string">"a"</span></span></span><br><span class="line">[root@localhost data]# echo $a</span><br><span class="line"></span><br><span class="line">[root@localhost data]# exit</span><br><span class="line">exit</span><br><span class="line"><span class="meta">#</span><span class="bash"> 回到父进程，一样能看到变量<span class="string">"a"</span></span></span><br><span class="line">[root@localhost data]# echo $a</span><br><span class="line">10</span><br><span class="line"><span class="meta">#</span><span class="bash"> 导出环境变量<span class="string">"a"</span>后，再次进入子进程shell</span></span><br><span class="line">[root@localhost data]# export a=$a</span><br><span class="line">[root@localhost data]# /bin/bash</span><br><span class="line"><span class="meta">#</span><span class="bash"> 此时子进程就能看到父进程的变量了，说明环境变量是会传递到子进程的！</span></span><br><span class="line">[root@localhost data]# echo $a</span><br><span class="line">10</span><br></pre></td></tr></table></figure></blockquote><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p>优点：</p><ol><li>生成的 dump.rdb 文件内容相对较小</li><li>类似 java 中的序列化，恢复速度相对较快</li></ol><p>缺点：</p><ol><li>不支持拉链，只有一个<code>dump.rdb</code></li><li>因为是时点性持久化，因此时点与时点之间窗口数据容易丢失，丢失的数据量较多</li></ol><blockquote><p>适合 把 redis 作为缓存，且缓存数据容忍丢失 的场景</p></blockquote><h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><p>​    为了解决 RDB 方式丢失数据较多的问题，另一种持久化 AOF 方式诞生了。</p><h4 id="实现方式-1"><a href="#实现方式-1" class="headerlink" title="实现方式"></a>实现方式</h4><p>​    AOF 实现原理简单，每次发生一笔写操作，就把操作记录到.aof文件中。在恢复的时候，从上往下一条条执行命令即可。.aof 就像一个记录了全量操作的日志文件，以下是一个 aof 文件内容示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">k2</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">aaa</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">k3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">aaa</span><br></pre></td></tr></table></figure><blockquote><p>在aof 文件中，</p><p>“$”代表下一行有几个字符；</p><p>“*”代表一个命令用了几行字符串</p><p>上面的文件内容代表以下3条指令：</p><ol><li>SELECT 0</li><li>set k2 aaa</li><li>set k3 aaa</li></ol></blockquote><p>​    <strong>那么问题来了</strong>：redis 运行了 10 年，开启了 AOF。十年后，redis挂了，请问如下问题：</p><ol><li><p>aof 文件有多大？可以无限大，例如 10T</p></li><li><p>恢复时会不会发生内存溢出？不会</p></li><li><p>恢复要多久时间？很长，比如 5 年，因为要一条命令一条命令去执行</p></li></ol><blockquote><p>日志文件无限大，硬盘早就满了，还得一直换硬盘。恢复数据得花好几年，这也叫可用？</p></blockquote><p>​    <strong>解决方案</strong>：redis 提供重写功能。重写功能在4.0之前及之后实现方式不一样，分开讨论</p><ul><li>在 redis 4.0 之前，.aof 是一个纯指令文件，触发重写后 cpu 会进行运算，实现以下两点：<ul><li>删除抵消的命令。如<code>set k1 aa</code>后又进行了<code>rem k1</code>，那么这两条命令就在 aof 文件中移除</li><li>合并重复命令。如执行了一万次<code>INCR k1</code>，可以合并成执行一次<code>INCRBY k1 10000</code></li></ul></li><li>在 redis 4.0 之后，默认是让重写功能不再进行运算，而是会生成 .rdb 文件，并将全量 rdb 内容放到 aof 的开始。之后增量的记录新来的写操作并 append 到 .aof 中。使得 .aof 变成了一个混合体，既有 rdb 的磁盘消耗小、恢复快，又有 aof 的全量数据特性。可以通过配置<code>aof-use-rdb-preamble no</code>使重写还是 redis 4.0 之前的逻辑</li></ul><h4 id="命令-1"><a href="#命令-1" class="headerlink" title="命令"></a>命令</h4><ul><li><code>BGREWRITEAOF</code>：异步触发重写，重写可以缩小 aof 文件内容</li></ul><h4 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 是否开启 aof，默认是不开启</span></span><br><span class="line">appendonly no</span><br><span class="line">appendfilename "appendonly.aof"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 对写操作都进行记录，一定会触发磁盘I/O，影响redis性能。 redis 提供了三种级别来控制 I/O 频率</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> appendfsync 设置调用 flush() 的频率。一旦调用flush()，就会将内核的 buffer 数据写到磁盘中，发生I/O</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> appendfsync always</span></span><br><span class="line">appendfsync everysec</span><br><span class="line"><span class="meta">#</span><span class="bash"> appendfsync no</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 当redis创建子进程，子进程在进行BGSAVE或者BGREWRITEAOF时，会对磁盘进行大量的I/O，此时是否允许触发appendfsync操作，默认是不允许触发。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 不允许触发可以避免I/O争抢，但是容易丢数据</span></span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下面两个配置合适触发aof的重写</span></span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认是达到64mb就触发重写，但是这个值在生产环境一定要调大，更改为1G级别起步</span></span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> aof 中可以使用 rdb，默认开启</span></span><br><span class="line">aof-use-rdb-preamble yes</span><br></pre></td></tr></table></figure><p><code>appendfsync</code>的三个选项含义和特点</p><ul><li><code>no</code>：redis 不主动触发 flush，让 os 自己按需调用。os 会在内核 buffer（4k左右）满时调用 flush，将 buffer 数据刷到 .aof 文件中。速度最快，可能丢失的数据量最大（不到一个 buffer 大小）</li><li><code>everysec</code>：redis 每秒调用一次 flush，丢失的数据量一定比 buffer 容量小，最糟情况是丢失近 buffer 容量数据，不过概率比<code>no</code>小。这是一种折中的方案，速度中等且丢失数据量中等</li><li><code>always</code>：每一次写操作都将调用 flush ，把 buffer 数据刷到 .aof 文件中。数据最多丢失一条，在调用 flush 或者 flush 还没结束时发生掉电。代价是速度最慢</li></ul><blockquote><p>调用flush()，就会将内核的 buffer 数据写到磁盘中，发生一次 I/O</p></blockquote><blockquote><p>在 redis 中，AOF 和 RDB 可以同时开启。如果开启了 AOF，只会用 AOF 去恢复，因为数据丢失少。</p></blockquote><h4 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h4><p>优点：</p><ol><li>4.0之后，可以将 aof 与 rbd 相结合，既避免了大量数据丢失，又实现了日志文件内容有限、恢复数据块的特点</li></ol><p>缺点：</p><ol><li>写操作伴随着往 .aof 里写文件，因此会增加磁盘I/O，降低 redis 性能</li><li>4.0 之前，.aof 文件可以很大，并且恢复时间慢</li></ol><blockquote><p>适合 把 redis 当数据库，不允许数据丢失 的场景</p></blockquote><h3 id="配置优化建议"><a href="#配置优化建议" class="headerlink" title="配置优化建议"></a>配置优化建议</h3><ol><li><code>auto-aof-rewrite-min-size 64mb</code>：该配置项值需要改大，达到G级别，比如 <code>5G</code></li><li><code>aof-use-rdb-preamble yes</code>：开启 aof 的混合模式</li><li><code>save 900 1</code>：开启 aof 混合模式后，将 rdb 触发频率调低。此时 rdb 只是个保底方案，无需太频繁进行</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/03-Redis使用进阶</title>
      <link href="/2020/03/20/Redis/03-Redis%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6/"/>
      <url>/2020/03/20/Redis/03-Redis%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis使用进阶"><a href="#Redis使用进阶" class="headerlink" title="Redis使用进阶"></a>Redis使用进阶</h1><h2 id="pipeline"><a href="#pipeline" class="headerlink" title="pipeline"></a>pipeline</h2><p>​    使用pipeline，实现一次发送多个命令，节省往返时间</p><blockquote><p>先安装 nc 命令行：<code>yum install -y nc</code></p><p>nc：Concatenate and redirect sockets，连接和重定向 socket 套接字</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 一次发送多个命令</span></span><br><span class="line">[root@localhost ~]# echo -e 'keys *\n set k2 a \n keys *' |nc localhost 6379   </span><br><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">k1</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">k3</span><br><span class="line">+OK</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">k2</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">k1</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">k3</span><br></pre></td></tr></table></figure><blockquote><p>使用 pipeline 时，服务器将被迫回复一个队列答复，占用很多内存。</p><p>因此，如果需要发送大量命令，最好把它们按照合理数量分批次的处理。</p><p>例如10K的命令，读回复，然后再发送另一个10k的命令，等等。这样速度几乎是相同的，但是在回复这10k命令队列需要非常大量的内存用来组织返回数据内容。</p></blockquote><blockquote><p>大量 pipeline 应用场景可通过 Redis 脚本（Redis 版本 &gt;= 2.6）得到更高效的处理，且脚本功能比 pipeline 更强大，可以获取命令的结果并供后续使用</p></blockquote><h2 id="Pub-Sub"><a href="#Pub-Sub" class="headerlink" title="Pub/Sub"></a>Pub/Sub</h2><p>​    订阅，取消订阅和发布实现了发布/订阅消息范式(引自wikipedia)，发送者（发布者）不是计划发送消息给特定的接收者（订阅者）。而是发布的消息分到不同的频道，不需要知道什么样的订阅者订阅。订阅者对一个或多个频道感兴趣，只需接收感兴趣的消息，不需要知道什么样的发布者发布的。这种发布者和订阅者的解耦合可以带来更大的扩展性和更加动态的网络拓扑。</p><blockquote><p><code>help @pubsub</code></p></blockquote><ol><li><p><code>PUBLISH channel message</code></p></li><li><p><code>SUBSCRIBE channel [channel ...]</code>：监听指定 channel 里的消息，不会监听到在该命令执行时刻之前发布的消息</p></li><li><p><code>PSUBSCRIBE pattern [pattern ...]</code>：同时监听多个满足 pattern 正则的 channel</p><p>下图是以微信为例，一个架构示例。</p></li></ol><p><img src="./pics/pubsub%E7%94%A8%E9%80%94.png" alt="pub/sub用途"></p><p>​    解决方案有两个：</p><ul><li><p>改架构，增加一个 redis 实例</p><p><img src="./pics/%E5%A2%9E%E5%8A%A0redis%E5%AE%9E%E4%BE%8B.png" alt="增加redis实例"></p></li><li><p>在 client 2 中将3步操作合并为一个事务，在下一节中说明</p></li></ul><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><blockquote><p><code>help @transactions</code></p></blockquote><ol><li><code>WATCH key [key ...]</code>：监听多个 key ，一般是在事务开启前就开始监听。当事务提交后，如果事务里要操作的 key 在之前就被监听了，并且这个 key 已被其它连接修改了，那么整个事务不会执行而直接返回<code>nil</code></li><li><code>MULTI</code>：开启事务的命令。一旦事务开启后，之后的命令都会被放到 queue 中，在提交事务时一并发出</li><li><code>DISCARD</code>：丢弃 queue 中所有的命令</li><li><code>EXEC</code>：提交事务</li><li><code>UNWATCH</code>：取消所有之前 <code>WATCH</code> 的 key</li></ol><blockquote><p>如果多个连接都有各自的事务，那么事务的执行顺序规则是：<font color='red'>谁的<code>exec</code>先到达，就先执行谁的事务</font>，与谁先开启事务无关</p></blockquote><p>什么时候事务会出错？</p><ol><li><p>事务在执行 <code>EXEC</code> 之前，入队的命令语法错误，或者内存不足。</p><p>这种情况会直接导致事务关闭，命令队列消失</p></li><li><p>可能在 <code>EXEC</code> 调用之后失败，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面。</p><p>在这种情况下，<strong>Redis 在事务中的某条命令执行失败时不进行回滚，而是继续执行事务中余下的命令！</strong></p></li></ol><h2 id="modules-RedisBloom"><a href="#modules-RedisBloom" class="headerlink" title="modules-RedisBloom"></a>modules-RedisBloom</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>​    Redis支持安装模块。这里以布隆过滤器模块为例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载</span></span><br><span class="line">wget https://github.com/RedisBloom/RedisBloom/archive/master.zip</span><br><span class="line">yum install -y unzip</span><br><span class="line">unzip master.zip</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 编译出 redisbloom.so 模块文件</span></span><br><span class="line">cd RedisBloom-master/</span><br><span class="line">make</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 装载 module</span></span><br><span class="line">vi /etc/redis/6379.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在配置文件里增加 loadmodule 配置：loadmodule /opt/redis/redisbloom.so</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意： module 文件的位置一定要配置成绝对路径，否则加载不了 redis 启动不起来</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启 redis 服务</span></span><br><span class="line">systemctl stop redis_6379</span><br><span class="line">systemctl start redis_6379</span><br></pre></td></tr></table></figure><h3 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h3><p>​    布隆过滤器是为了解决缓存穿透问题。</p><blockquote><p>什么是缓存穿透？</p><p>例如淘宝商品搜索功能，有一个黑客，用多个客户端进行商品关键字搜索，搜索的字眼根本不是商品，不在任何数据库中，因此缓存不会命中，那么请求就会穿透到数据库层。一旦无数个请求都穿透到数据库层，数据库就可能会崩掉。</p></blockquote><p>​    它是如何解决的呢？布隆过滤器底层维护了一个 bitmap ，要对搜索进行过滤，先需要把所有的商品都加到布隆过滤器中，一个商品的添加流程是：</p><ol><li><p>对商品做十几个不同的 hash 函数计算，得到十几个结果值</p></li><li><p>把结果值与 bitmap 中的一个位对应，将该位值置为”1”</p><p>当来了一个搜索关键字，需要判断是否存在该商品，流程如下：</p></li><li><p>对该商品做一次 hash 函数计算，得到结果值</p></li><li><p>找到结果值对应 bitmap 位上的值，检查值是否为”1”</p></li><li><p>为 “1” 则换一个 hash 函数进行计算，重复1、2、3步骤，直到算完所有的 hash 函数，都为 “1” 代表存在该商品</p></li><li><p>为 “0” 则代表该商品不存在，直接返回</p></li></ol><blockquote><p>注意：当数据库中增加了商品种类时，也需要同步在布隆过滤器中进行添加</p></blockquote><p><img src="./pics/bloom%E5%8E%9F%E7%90%86%E5%9B%BE.png" alt="布隆过滤器原理"></p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; BF.MADD bikes didi  mobai halou</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br><span class="line">3) (integer) 1</span><br><span class="line">127.0.0.1:6379&gt; BF.INFO bikes</span><br><span class="line"> 1) Capacity</span><br><span class="line"> 2) (integer) 100</span><br><span class="line"> 3) Size</span><br><span class="line"> 4) (integer) 290</span><br><span class="line"> 5) Number of filters</span><br><span class="line"> 6) (integer) 1</span><br><span class="line"> 7) Number of items inserted</span><br><span class="line"> 8) (integer) 4</span><br><span class="line"> 9) Expansion rate</span><br><span class="line">10) (integer) 2</span><br><span class="line">127.0.0.1:6379&gt; BF.EXISTS bikes didi</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; BF.MEXISTS bikes ofo yonganxing</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 0</span><br></pre></td></tr></table></figure><blockquote><p>为什么没有类似 <code>BF.DEL</code> 、<code>BF.REM</code> 命令？</p><p>因为布隆过滤器的原理导致它没法支持删除元素操作，因为不同的元素可能会在 bitmap 同一位上发生碰撞，都设置成了 “1”。 如果其中一个元素删除了，把它对应位都还原成0，那么和该元素发生碰撞的其它元素也就不存在了，所以没法实现删除功能</p></blockquote><blockquote><p>客户端、服务器使用布隆过滤器的三种方式，根据场景做具体选型</p><p><img src="./pics/client-redis-with-bloom.png" alt="client-redis-with-bloom"></p></blockquote><h3 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h3><h4 id="误判"><a href="#误判" class="headerlink" title="误判"></a>误判</h4><p>​    多个商品的多个 hash 函数结果值，可能会对应到 bitmap 同一位上，产生碰撞，因此只能概率解决问题，不可能百分百阻挡，误判概率常低于 1%。</p><blockquote><p>如何解决这个问题？</p><p>在穿透后打到 mysql 里，mysql 会返回空或者报错，client 发现是空或者商品不存在后，在 redis 中增加这个穿透了布隆过滤器的关键字信息。以后当再有人查同样的关键字时，redis 直接返回空，不再发生二次穿透</p></blockquote><h4 id="无法删除"><a href="#无法删除" class="headerlink" title="无法删除"></a>无法删除</h4><p>​    为了解决 bloom 无法删除，<code>cuckoo filter</code>布谷鸟过滤器横空出世。</p><p>​    布谷鸟过滤器对于 bloom 过滤器有以下优势：查询性能强、空间利用效率高、支持反向操作（删除）以及支持计数。</p><p>​    但布谷鸟并没有想象中那么好，有很多问题：</p><ol><li>bitmap 长度必须是 2 的指数，而 bloom 并没有长度要求</li><li>删除操作有个致命弱点，必须确保每个元素不会被插入指定的 x 次，这个 x 是根据一定规则算出来的一个固定值。这在实际使用中根本不可能保证，因为还需要额外空间存储每个元素插入的次数</li><li>无法准确估计内部元素数量</li></ol><blockquote><p>参考文章：<a href="https://cloud.tencent.com/developer/article/1447177" target="_blank" rel="noopener">布隆过滤器过时了，未来属于布谷鸟过滤器？</a></p></blockquote><h2 id="Redis作为数据库和作为缓存的区别"><a href="#Redis作为数据库和作为缓存的区别" class="headerlink" title="Redis作为数据库和作为缓存的区别"></a>Redis作为数据库和作为缓存的区别</h2><p>​    Redis作为缓存，相比数据库数据，有如下特点：</p><ol><li><p>缓存数据准确性不重要</p></li><li><p>缓存数据不需要全量</p></li><li><p>缓存数据应随着访问而变化</p></li><li><p>内存是有限的，在内存不够情况下，应只保留热数据</p><p>那么问题来了，redis 如何做到随着业务变化，只保留热数据，避免内存成为瓶颈？</p></li></ol><h3 id="设置过期时间"><a href="#设置过期时间" class="headerlink" title="设置过期时间"></a>设置过期时间</h3><p>​    有的业务逻辑，需要对 key 的有效期进行管理，如分布式锁。当到了过期时间后，key 就被删除了，内存也就释放了。</p><h4 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在具体命令里设置过期时间</span></span><br><span class="line">127.0.0.1:6379&gt; set k1 10 EX 10</span><br><span class="line">OK</span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过 TTL 命令，查看 k1 剩余时间</span></span><br><span class="line">127.0.0.1:6379&gt; TTL k1</span><br><span class="line">(integer) 6</span><br><span class="line">127.0.0.1:6379&gt; TTL k1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 返回 -2 代表 k1 已过期</span></span><br><span class="line">(integer) -2</span><br><span class="line">127.0.0.1:6379&gt; SET k2 aa</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; TTL k2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 返回 -1 代表 k2 不会过期</span></span><br><span class="line">(integer) -1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 通用的设置 key 过期时间的命令：EXPIRE</span></span><br><span class="line">127.0.0.1:6379&gt; EXPIRE k2 10</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; TTL k2</span><br><span class="line">(integer) 5</span><br><span class="line"><span class="meta">#</span><span class="bash"> 对已有过期时间的 key 再次设置过期时间时，会更新有效期</span></span><br><span class="line">127.0.0.1:6379&gt; EXPIRE k2 10</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; TTL k2</span><br><span class="line">(integer) 9</span><br><span class="line"><span class="meta">#</span><span class="bash"> 读操作 不会更新过期时间</span></span><br><span class="line">127.0.0.1:6379&gt; GET k2</span><br><span class="line">"aa"</span><br><span class="line">127.0.0.1:6379&gt; TTL k2</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; SET k2 bb</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; EXPIRE k2 10</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; TTL k2</span><br><span class="line">(integer) 7</span><br><span class="line"><span class="meta">#</span><span class="bash"> 写操作，直接剔除过期时间</span></span><br><span class="line">127.0.0.1:6379&gt; SET k2 cc</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; TTL k2</span><br><span class="line">(integer) -1</span><br></pre></td></tr></table></figure><h4 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h4><ol><li><code>EXPIRE key seconds</code>：通用的过期时间设置方式，指定剩余有效时间（倒计时）</li><li><code>EXPIREAT key timestamp</code>：通用的过期时间设置方式，指定删除的时间戳，到达改时间就删除（定时）</li><li><code>TTL key</code>：查看指定 key 的剩余存活时间<ul><li>返回 “-1” 代表永不过期</li><li>返回 “-2” 代表已经过期</li><li>返回 非负数代表剩余有效时间，单位是秒</li></ul></li><li>对已有过期时间的 key 再次通过 <code>EXPIRE</code> 设置过期时间，会更新过期时间</li><li>读操作，不会影响过期时间</li><li>写操作，会直接剔除过期时间</li></ol><h4 id="如何淘汰过期的-keys"><a href="#如何淘汰过期的-keys" class="headerlink" title="如何淘汰过期的 keys"></a>如何淘汰过期的 keys</h4><p>​    redis 是如何实现过期的？有两种方式，主动和被动</p><ul><li><p>被动：当一些客户端尝试访问某个 key 时，发现 key 已经过期，就返回 <code>nil</code> 并删除数据释放内存</p><p>只有被动方式是不够的，有些 key 已过期且一直没人访问，这些 key 却一直在内存中，因此还需主动方式</p></li><li><p>主动：定时随机测试部分 keys 的过期时间，所有这些过期的 keys 将会从内存中删除。</p><p>具体就是Redis每秒10次做的事情：</p><ol><li>随机的测试20个 keys 进行过期检测</li><li>删除所有已经过期的 keys</li><li>如果有多于25%的 keys 过期，重复步骤1</li></ol><p>被动和主动组合使用，最终达到的效果是：牺牲少量内存，保住 redis 的性能！</p></li></ul><h3 id="设置缓存淘汰算法"><a href="#设置缓存淘汰算法" class="headerlink" title="设置缓存淘汰算法"></a>设置缓存淘汰算法</h3><p>​    内存是有限的，随着访问的变化，应该删除掉冷数据，避免内存成为瓶颈。</p><h4 id="使用方式-1"><a href="#使用方式-1" class="headerlink" title="使用方式"></a>使用方式</h4><ol><li><p>如何设置 redis 使用的内存空间大小</p><p>在 redis 的配置文件 <code>redis.conf</code> 中，通过<code>maxmemory &lt;bytes&gt;</code>字段进行设置。对于64位系统，默认值代表没有内存限制。</p></li><li><p>如何设置数据回收策略<br>同样在 <code>redis.conf</code> 中，通过 <code>maxmemory-policy noeviction</code>进行设置，默认是是 <code>noeviction</code></p></li><li><p>支持的回收策略</p><ul><li><code>noeviction</code>：不做回收，当没内存时直接返回错误。这是把 redis 当作数据库使用时的回收策略</li><li><code>volatile-lru</code></li><li><code>allkeys-lru</code>：很常用，做缓存时如果不指定选什么策略，那就选它</li><li><code>volatile-lfu</code></li><li><code>allkeys-lfu</code></li><li><code>volatile-random</code>：适合 单一的 redis 实例实现缓存及持久化一些键 的场景</li><li><code>allkeys-random</code>：适合循环访问，所有的键被连续的扫描场景</li><li><code>volatile-ttl</code>：移除刚刚到期（较小的TTL）的 key。适合 想要通过对象的TTL值来决定哪些对象应该被过期 的场景</li></ul><p><code>volatile</code>前缀的代表移出范围是所有过期的 keys，如果所有对象都没有过期，那么效果就和<code>noeviction</code>一样；<code>allkeys</code>前缀代表针对所有的 keys</p><p><code>lru</code>代表移除最长时间没用的 keys；<code>lfu</code>代表移除最少使用次数的 keys；<code>random</code>代表随机移除</p></li></ol><p><img src="./pics/redis%E4%BD%9C%E4%B8%BA%E7%BC%93%E5%AD%98%E7%9A%84%E9%87%8D%E7%82%B9.png" alt="redis作为缓存的重点"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/02-Redis数据类型和使用场景</title>
      <link href="/2020/03/20/Redis/02-Redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
      <url>/2020/03/20/Redis/02-Redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis数据类型和使用场景"><a href="#Redis数据类型和使用场景" class="headerlink" title="Redis数据类型和使用场景"></a>Redis数据类型和使用场景</h1><h2 id="二进制安全机制"><a href="#二进制安全机制" class="headerlink" title="二进制安全机制"></a>二进制安全机制</h2><p>​    二进制安全的意思就是，redis只关心二进制化的字符串，不关心具体格式，只会以<strong>字节流</strong>存取数据，不会妄图以某种特殊格式解析数据。</p><p>​    在进入客户端命令行时，可以通过增加<code>redis-cli --row</code>参数，使redis客户端尝试进行编码后返回。</p><h2 id="string"><a href="#string" class="headerlink" title="string"></a>string</h2><h3 id="1-字符串"><a href="#1-字符串" class="headerlink" title="1. 字符串"></a>1. 字符串</h3><h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="增删改查："><a href="#增删改查：" class="headerlink" title="增删改查："></a>增删改查：</h5><ol><li><code>SET key value [expiration EX seconds|PX milliseconds] [NX|XX]</code><ul><li><code>set k1 hello EX 10</code>：插入k1键，10秒后过期</li><li><code>set k1 hello PX 10</code>：插入k1键，10毫秒后过期</li><li><code>set k1 hello NX</code>：只有k1键不存在时，才会设置value值</li><li><code>set k1 hello XX</code>：只有k1键存在时，才会设置value值</li></ul></li><li><code>MSET key value [key value ...]</code></li><li><code>MSETNX key value [key value ...]</code>：一次设置多组kv，只有在k都不存在时。多组kv中有任意一个key存在，那么整条命令都会失败，即不会设置任何value</li><li><code>PSETEX key milliseconds value</code>：和<code>SET key value PX milliseconds</code>一样</li><li><code>SETEX key seconds value</code>：和<code>SET key value EX seconds</code>一样</li><li><code>SETNX key value</code>：和<code>SET key NX value</code>一样</li><li><code>DEL key</code></li><li><code>GET key</code></li><li><code>MGET key [key ...]</code>：一次获取多个key的value</li><li><code>GETSET key</code></li><li><code>APPEND key value</code></li><li><code>GETRANGE key start end</code><ul><li><code>GETRANGE k1 0 4</code>：获取k1的value值中第0到第4共5个字符，双闭区间</li><li><code>GETRANGE k1 -5 -1</code>：获取k1的value值中倒数第5到最后一个共5个字符，双闭区间</li></ul></li><li><code>SETRANGE key offset value</code><ul><li><code>SETRANGE k1 6 aaaa</code>：把k1键对应的值，从第7个字符开始用<code>aaaa</code>覆盖。比如原来value是<code>hello world</code>，覆盖之后是<code>hello aaaad</code>。如果<code>offset</code>超过值的当前长度，那么值长度会增加，中间空缺的位置用ASCII码中空字符<code>\x00</code>填充</li></ul></li><li><code>STRLEN key</code></li></ol><h4 id="字符串类型值的三种底层编码方式"><a href="#字符串类型值的三种底层编码方式" class="headerlink" title="字符串类型值的三种底层编码方式"></a>字符串类型值的三种底层编码方式</h4><p>​    通过<code>OBJECT encoding key</code>可以看到指定key的value在底层是什么编码方式。对于字符串类型值，redis有3种编码：</p><ul><li>int：当值是整数，且可以采用long类型表示时</li><li>embstr：当值的长度不大于44个字符时，用embstr编码。embstr编码的对象只有一次内存调用，速度更快，但是只读。当对embstr编码值进行修改时，会先进行编码转换，编程raw编码，再执行修改操作</li><li>raw：当值的长度大于44个字符时，或者embstr编码的值发生了修改（如通过<code>append</code>命令）</li></ul><h3 id="2-数值"><a href="#2-数值" class="headerlink" title="2. 数值"></a>2. 数值</h3><h4 id="常用命令-1"><a href="#常用命令-1" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="数值计算："><a href="#数值计算：" class="headerlink" title="数值计算："></a>数值计算：</h5><ol><li><code>INCR key</code></li><li><code>INCRBY key increment</code></li><li><code>INCRBYFLOAT key increment</code>：对指定key对应值与increment做加法运算。increment可以是小数或者负数，一旦成功执行该命令后，key对应值编码就会变成embstr，如果value中带有小数点”.”，那么其他int类型命令（如 <code>INCR</code>、<code>DECRBY</code>等）就无法使用了</li><li><code>DECR key</code></li><li><code>DECRBY key decrement</code></li></ol><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p>​    做 [有规定生存时间内的] 计数器，如秒杀中的商品库存、详情页中的点赞和评论数。</p><p>​    唯一 id 生成器。</p><p>​    在数据不需要强一致、持久化的场景下，使用redis在内存中进行操作，可以规避并发、规避数据库的事务，提升性能降低数据占用磁盘的空间</p><h3 id="3-位图bitmap"><a href="#3-位图bitmap" class="headerlink" title="3. 位图bitmap"></a>3. 位图bitmap</h3><h4 id="常用命令-2"><a href="#常用命令-2" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="增删改查：-1"><a href="#增删改查：-1" class="headerlink" title="增删改查："></a>增删改查：</h5><ol><li><code>GETBIT key offset</code>：获取指定key对应value中，位下标是offset的值。返回值不是”0”就是”1”</li><li><code>SETBIT key offset value</code></li><li><code>BITCOUNT key [start end]</code>：返回从start下标字节开始，到end下标字节结束，这串字节里位上值为“1”的个数</li><li><code>BITPOS key bit [start] [end]</code>：<code>bit</code>可以取”0”或”1”值，代表从start下标字节开始end下标字节结束，第一个出现位值是<code>bit</code>的位下标。返回”-1”代表不存在位值等于<code>bit</code></li></ol><h5 id="位运算："><a href="#位运算：" class="headerlink" title="位运算："></a>位运算：</h5><ol><li><code>BITOP operation destkey key [key ...]</code>：对bitmap做运算<ul><li><code>BITOP AND destkey key [key ...]</code> ，对一个或多个 <code>key</code> 求逻辑与，并将结果保存到 <code>destkey</code> </li><li><code>BITOP OR destkey key [key ...]</code> ，对一个或多个 <code>key</code> 求逻辑或，并将结果保存到 <code>destkey</code> </li><li><code>BITOP XOR destkey key [key ...]</code> ，对一个或多个 <code>key</code> 求逻辑异或，并将结果保存到 <code>destkey</code> </li><li><code>BITOP NOT destkey key</code> ，对给定 <code>key</code> 求逻辑非，并将结果保存到 <code>destkey</code> </li></ul></li><li><code>BITFIELD key [GET type offset][SET type offset value] [INCRBY type offset increment][OVERFLOW WRAP|SAT|FAIL]</code>：该命令将 Redis 字符串视为一个位数组，并且能够处理具有不同位宽和任意非（必要）对齐偏移量的特定整数字段</li></ol><p><img src="./pics/bitmap.png" alt="bitmap"></p><h4 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h4><ol><li><p>有一个用户系统，需要统计用户登录天数，且支持指定时间窗口（如2020年第一个月，618当天 是否登录）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> userid用户2020年第1天登录了，设置第0下标位为1</span></span><br><span class="line">127.0.0.1:6379&gt; SETBIT userid 0 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> userid用户2020年第16天登录了，设置第15下标位为1</span></span><br><span class="line">127.0.0.1:6379&gt; SETBIT userid 15 1</span><br><span class="line">0</span><br><span class="line"><span class="meta">#</span><span class="bash"> userid用户2020年最后一天登录了，设置第364位为1</span></span><br><span class="line">127.0.0.1:6379&gt; SETBIT userid 364 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 统计userid用户一年登录天数</span></span><br><span class="line">127.0.0.1:6379&gt; BITCOUNT userid</span><br><span class="line">3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 统计userid用户最后一个月登录天数</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 334位代表12月第一天</span></span><br><span class="line">127.0.0.1:6379&gt; GETBIT userid 334</span><br><span class="line">0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 335位代表12月第二天</span></span><br><span class="line">127.0.0.1:6379&gt; GETBIT userid 335</span><br><span class="line">0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 统计最后29天总登录天数。-1到-4一共是32个字节，由于最后一个字节的8位只用了前5位（365/8=45余5），因此这32个字节其实只有29个是有效的</span></span><br><span class="line">127.0.0.1:6379&gt; BITCOUNT userid -4 -1</span><br><span class="line">1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将三个返回值累加就是该用户最后一个月的总登录天数</span></span><br></pre></td></tr></table></figure><p>数据结构：每条数据的key是用户唯一表示，值的每一位代表不同的状态</p><p><img src="./pics/bitmap-1.png" alt="bitmap-1"></p></li><li><p>有一个大型电商，618要做活动，在当天登录了的用户会送礼物，请预估需要准备多少货</p><p>​    用户分为僵尸用户和活跃用户等，对于僵尸用户，登录的概率是极小的，因此不可能数据库里有多少用户就备多少数量的货</p><p>​    这个问题的本质是支持随机窗口的活跃用户统计，统计出近期内一段时间内登陆的用户数（需要进行去重，因为一个用户只会发放一份礼物），然后这个活跃用户数再扩一定的百分比（比如扩个30%、50%），就是预估的备货数量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 10代表某个特定用户的id，1代表这个用户登陆了</span></span><br><span class="line">127.0.0.1:6379&gt; SETBIT 20200101 10 1</span><br><span class="line">0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 15号用户在2020 01 01日登陆了</span></span><br><span class="line">127.0.0.1:6379&gt; SETBIT 20200101 15 1</span><br><span class="line">0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 15号用户在2020 01 02日又登陆了</span></span><br><span class="line">127.0.0.1:6379&gt; SETBIT 20200102 15 1</span><br><span class="line">0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 33号用户在2020 01 02日登陆了</span></span><br><span class="line">127.0.0.1:6379&gt; SETBIT 20200102 33 1</span><br><span class="line">0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 统计这两天共有多少用户进行了登陆，做or运算</span></span><br><span class="line">127.0.0.1:6379&gt; BITOP or totalcount 20200101 20200102</span><br><span class="line">5</span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取计算结果中共有多少位值为1，即为总登录用户数</span></span><br><span class="line">127.0.0.1:6379&gt; BITCOUNT totalcount</span><br><span class="line">3</span><br></pre></td></tr></table></figure><p>数据结构：每条数据的key代表日期，值的每一位对应一个用户</p><p><img src="./pics/bitmap-2.jpg" alt="bitmap-2"></p></li></ol><h2 id="list"><a href="#list" class="headerlink" title="list"></a>list</h2><p>​    <font color='red'>存取有序</font>、不去重、集合内不排序</p><h3 id="常用命令-3"><a href="#常用命令-3" class="headerlink" title="常用命令"></a>常用命令</h3><p>​    list命令中，有“R”开头的命令，代表Right；有“L”开头的命令，代表Left或者List；有“B”开头的命令，代表Block</p><h4 id="增删改查：-2"><a href="#增删改查：-2" class="headerlink" title="增删改查："></a>增删改查：</h4><ol><li><code>LPUSH key value [value ...]</code></li><li><code>RPUSH key value [value ...]</code></li><li><code>LPUSHX key value</code>：只在存在key时成功</li><li><code>RPUSHX key valu</code></li><li><code>LINSERT key BEFORE|AFTER pivot value</code>：在指定位置插入元素。<ul><li><code>LINSERT k1 before e 1</code>：从左往右遍历list，在第一个值是“e”的前面插入元素值”1”</li><li><code>LINSERT k1 after 1 2</code></li></ul></li><li><code>LREM key count value</code>：count可以是正数，代表从左往右数count个数的value进行移除；count可以是负数，代表从右往左数<ul><li><code>LREM k1 2 a</code>：从左往右依次删除2个值为“a”的元素，返回删除元素的个数</li><li><code>LREM k1 -2 b</code>：从右往左删2个”b”元素</li></ul></li><li><code>LTRIM key start stop</code>：删除 start 索引前面的和 stop 索引后面的元素。索引支持正负值<ul><li><code>lrange k1 1 -2</code>：删除k1首尾两个元素</li></ul></li><li><code>LPOP key</code>：</li><li><code>RPOP key</code>：</li><li><code>RPOPLPUSH source destination</code>：移除 source key对应list中的最右边一个元素，并把移除的元素值加到 destination key对应list的左边</li><li><code>LRANGE key start stop</code>：返回 start 索引开始，stop 索引结束的列表，索引支持正负</li><li><code>LLEN key</code></li></ol><h4 id="索引相关操作："><a href="#索引相关操作：" class="headerlink" title="索引相关操作："></a>索引相关操作：</h4><ol><li><code>LINDEX key index</code></li><li><code>LSET key index value</code>：</li></ol><h4 id="阻塞操作："><a href="#阻塞操作：" class="headerlink" title="阻塞操作："></a>阻塞操作：</h4><ol><li><code>BLPOP key [key ...] timeout</code></li><li><code>BRPOP key [key ...] timeout</code></li><li><code>BRPOPLPUSH source destination timeout</code></li></ol><h3 id="使用场景-2"><a href="#使用场景-2" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>同向命令（<code>lpush</code>、<code>lpop</code>）实现栈</li><li>反向命令（<code>lpush</code>、<code>rpop</code>）实现队列</li><li>索引操作（<code>LINDEX</code>、<code>LSET</code>）实现数组</li><li>阻塞操作（<code>BLPOP</code>、<code>LPOP</code>）实现阻塞、先进先出的单播队列</li></ul><h2 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h2><h3 id="常用命令-4"><a href="#常用命令-4" class="headerlink" title="常用命令"></a>常用命令</h3><h4 id="增删改查：-3"><a href="#增删改查：-3" class="headerlink" title="增删改查："></a>增删改查：</h4><ol><li><p><code>HSET key field value</code></p></li><li><p><code>HMSET key field value [field value ...]</code></p></li><li><p><code>HSETNX key field value</code>：field不存在时才会成功</p></li><li><p><code>HDEL key field [field ...]</code></p></li><li><p><code>HGET key field</code></p></li><li><p><code>HMGET key field [field ...]</code></p></li><li><p><code>HKEYS</code></p></li><li><p><code>HVALS</code></p></li><li><p><code>HGETALL</code></p></li><li><p><code>HSCAN key cursor [MATCH pattern] [COUNT count]</code>：返回从 cursor 开始的部分数据及下一次 cursor 位置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> keys *，在数据量大的情况下会阻塞很久时间</span></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line"> 1) "[[kkalsd"</span><br><span class="line"> 2) "k0"</span><br><span class="line"> 3) "czwspk"</span><br><span class="line"> 4) "k"</span><br><span class="line"> 5) "k1"</span><br><span class="line"> 6) "xx"</span><br><span class="line"> 7) "test"</span><br><span class="line"> 8) "a"</span><br><span class="line"> 9) "c"</span><br><span class="line">10) "k2"</span><br><span class="line">11) "mykey"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过 SCAN 命令分批获取</span></span><br><span class="line">127.0.0.1:6379&gt; SCAN 0 count 3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 返回下一个key的cursor</span></span><br><span class="line">1) "2"</span><br><span class="line">2) 1) "[[kkalsd"</span><br><span class="line">   2) "k0"</span><br><span class="line">   3) "c"</span><br><span class="line">127.0.0.1:6379&gt; SCAN 2 count 3</span><br><span class="line">1) "10"</span><br><span class="line">2) 1) "k"</span><br><span class="line">   2) "k1"</span><br><span class="line">   3) "xx"</span><br><span class="line">127.0.0.1:6379&gt; SCAN 10 count 6</span><br><span class="line"><span class="meta">#</span><span class="bash"> cursor 归零，代表keys遍历完了</span></span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "test"</span><br><span class="line">   2) "czwspk"</span><br><span class="line">   3) "k2"</span><br><span class="line">   4) "a"</span><br><span class="line">   5) "mykey"</span><br></pre></td></tr></table></figure></li><li><p><code>HEXISTS key field</code>：返回值“1”代表存在，“0”代表不存在</p></li><li><p><code>HLEN key</code></p></li><li><p><code>HSTRLEN key field</code></p></li></ol><h4 id="数值计算：-1"><a href="#数值计算：-1" class="headerlink" title="数值计算："></a>数值计算：</h4><ol><li><p><code>HINCRBY key field increment</code>：increment可以是负数</p></li><li><p><code>HINCRBYFLOAT key field increment</code></p></li></ol><h3 id="使用场景-3"><a href="#使用场景-3" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>对field进行数值计算，适用于点赞数、收藏数</li><li><code>HGETALL</code>一次获取全部键值，适用于详情页各种字段值</li></ul><h2 id="set"><a href="#set" class="headerlink" title="set"></a>set</h2><p>​        <font color='red'>去重</font>、集合内不排序、存取无序</p><h3 id="常用命令-5"><a href="#常用命令-5" class="headerlink" title="常用命令"></a>常用命令</h3><h4 id="增删改查：-4"><a href="#增删改查：-4" class="headerlink" title="增删改查："></a>增删改查：</h4><ol><li><code>SADD key member [member ...]</code></li><li><code>SREM key member [member ...]</code></li><li><code>SMOVE source destination member</code></li><li><code>SMEMBERS key</code>：返回set中所有值。当数据很大时，影响主机网卡性能和吞吐量。如果要使用该功能，最好把用这个功能的redis单独放到几台服务器上，这几台服务器上不跑其它服务</li><li><code>SCARD key</code>：获取set元素个数</li><li><code>SISMEMBER key member</code></li><li><code>SSCAN key cursor [MATCH pattern] [COUNT count]</code></li></ol><h4 id="交并差集："><a href="#交并差集：" class="headerlink" title="交并差集："></a>交并差集：</h4><ol><li><code>SINTER key [key ...]</code>和<code>SINTERSTORE destination key [key ...]</code>：多个key对应set间取交集。命令中有”STORE”代表存储，”destination”是存储到哪个key里</li><li><code>SUNION key [key ...]</code>和<code>SUNIONSTORE destination key [key ...]</code>：取并集</li><li><code>SDIFF key [key ...]</code>和<code>SDIFFSTORE destination key [key ...]</code>：差集，方向通过key顺序来实现<ul><li><code>SDIFF k1 k2</code>：k1 - k2的差集</li><li><code>SDIFF k2 k1</code>：k2 - k1的差集，和上面的结果不一样</li></ul></li></ol><h4 id="随机事件："><a href="#随机事件：" class="headerlink" title="随机事件："></a>随机事件：</h4><ol><li><code>SRANDMEMBER key [count]</code>：count代表随记取出元素的个数。为正数则表示不会重复，为负数表示可以重复</li><li><code>SPOP key [count]</code>：这个count不支持负数</li></ol><h3 id="使用场景-4"><a href="#使用场景-4" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li><p>基于随机事件，可以实现抽奖</p><p>​    抽奖分好多种：</p><ul><li><p>人数大于礼物数</p><ul><li>可重复：<code>SRANDMEMBER k1 3</code>，k1中存人的唯一标识，3是礼物数</li><li>不可重复：<code>SRANDMEMBER k1 -3</code></li></ul></li><li><p>礼物数大于人数，每人可获得多个礼物</p><p><code>SRANDMEMBER k1 -100</code>，k1中存人的唯一标识，即时k1中没有100个元素，也会抽出100个人</p></li><li><p>分阶段抽，不重复</p><p>第一阶段抽3个人，抽中的人不参与第二阶段抽奖：<code>SPOP k1 3</code>；</p><p>第二阶段抽1人：<code>SPOP k1 1</code></p></li></ul></li><li><p>通过交并差集，实现关注模型中，可能认识的人</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 用户a，认识 a b c</span></span><br><span class="line">127.0.0.1:6379&gt; SADD a a b c </span><br><span class="line">(integer) 3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 用户b， 认识 a b c d</span></span><br><span class="line">127.0.0.1:6379&gt; SADD b a b c d</span><br><span class="line"><span class="meta">#</span><span class="bash"> 用户c， 认识 a b c d</span></span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; SADD c a b c d</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 求用户a可能认识的人</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1. 将用户a认识的 b 和 c取并集</span></span><br><span class="line">127.0.0.1:6379&gt; SINTERSTORE bc b c</span><br><span class="line">(integer) 4</span><br><span class="line"><span class="meta">#</span><span class="bash">  2. 将1.结果与a 取差集</span></span><br><span class="line">127.0.0.1:6379&gt; SDIFF bc a</span><br><span class="line">1) "d"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 结果是 用户a可能认识 d</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="sorted-set"><a href="#sorted-set" class="headerlink" title="sorted_set"></a>sorted_set</h2><p>​    <font color='red'>去重、集合内按分值排序</font>、存取无序。物理内存左小右大</p><p>​    分三个维度，成员、分值、排名</p><h3 id="常用命令-6"><a href="#常用命令-6" class="headerlink" title="常用命令"></a>常用命令</h3><p>​    因为”S”开头的命令被set用掉了，所以sorted_set命令开头的字母就改成了最后一个字母“Z”</p><h4 id="增删改查：-5"><a href="#增删改查：-5" class="headerlink" title="增删改查："></a>增删改查：</h4><ol><li><p><code>ZADD key [NX|XX] [CH] [INCR] score member [score member ...]</code></p><ul><li><code>NX</code>：只有在成员不存在时操作才会成功</li><li><code>XX</code>：只有在成员存在时操作才会成功</li><li><code>CH</code>：当没有<code>CN</code>时候，<code>ZADD</code>会返回新添加的成员数。当加上<code>CN</code>后，返回被修改的成员数</li><li><code>INCR</code>：如果原来存在指定的 member，则将新的 socre与原来的 score 进行加法操作，而不是用新的 score更新原来的 score</li></ul></li><li><p><code>ZPOPMAX key [count]</code></p></li><li><p><code>ZPOPMIN key [count]</code></p></li><li><p><code>ZREM key member [member ...]</code></p></li><li><p><code>ZREMRANGEBYLEX key min max</code>：带有<code>LEX</code>的命令，只有当 sorted_set 中所有成员 score 相等时才有用。删除符合 “成员区间”的成员</p><blockquote><p>“成员区间” 对应命令中的 min 和 max，规则如下：</p><p>min 为 “-“ 代表从0下标开始，闭区间，包括0下标</p><p>max 为 “+” 代表到最后一个元素为止，闭区间</p><p>“(“ 代表开区间</p><p>“[“ 代表封区间</p></blockquote><p>示例：</p><p><code>v1</code>、<code>v2</code>、<code>v3</code>、<code>v4</code>成员 score 一样</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGE k1 0 -1 withscores</span><br><span class="line">1) "v1"</span><br><span class="line">2) "1"</span><br><span class="line">3) "v2"</span><br><span class="line">4) "1"</span><br><span class="line">5) "v3"</span><br><span class="line">6) "1"</span><br><span class="line">7) "v4"</span><br><span class="line">8) "1"</span><br></pre></td></tr></table></figure><ul><li><code>ZREMRANGEBYLEX k1 - +</code>：删除全部成员</li><li><code>ZREMRANGEBYLEX k1 - (v2</code>：删除 “v1”</li><li><code>ZREMRANGEBYLEX k1 - [v2</code>：删除 “v1”和”v2”</li><li><code>ZREMRANGEBYLEX k2 [v2 +</code>：删除 “v2”、”v3” 和 “v4”</li></ul></li><li><p><code>ZREMRANGEBYRANK key start stop</code>：删除符合 rank 区间的成员</p></li><li><p><code>ZREMRANGEBYSCORE key min max</code>：删除符合 score 区间的成员</p></li><li><p><code>ZSCORE key member</code></p></li><li><p><code>ZCOUNT key min max</code>：返回 score 符合区间的成员个数</p></li><li><p><code>ZLEXCOUNT key min max</code></p></li><li><p><code>ZCARD key</code></p></li><li><p><code>ZSCAN key cursor [MATCH pattern] [COUNT count]</code></p><p>sorted_set 命令一般是按 score 从小到大的顺序返回，以下命令支持加<code>PRV</code>，使返回内容按照 score 从大到小顺序</p></li><li><p><code>Z[REV]RANGE  key start stop [WITHSCORES]</code></p></li><li><p><code>Z[REV]RANGEBYLEX key min max [LIMIT offset count]</code></p><ul><li><code>offset</code>：下标偏移量，即跳过前 <code>offset</code> 个数成员</li><li><code>count</code>：返回的最大成员个数</li></ul><p><code>offset</code> 和 <code>count</code> 其实是做分页用的</p></li><li><p><code>Z[REV]RANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]</code></p></li><li><p><code>Z[REV]RANK key member</code>：返回 key 对应 sorted_set 中指定 成员的 rank 排名</p></li></ol><h4 id="交并集："><a href="#交并集：" class="headerlink" title="交并集："></a>交并集：</h4><p>​    在取交集、并集的时候，和 set 不同， sorted_set 必须把结果进行存储。交集、并集操作是对 set 中成员进行操作的， 对于成员各自的 score ，需要给出结果中成员的 score 计算方式，因此有<code>WEIGHTS</code>和<code>AGGREGATE</code>选项。</p><blockquote><p>例：成员 ryan 存在于k1 和 k2 所对应 set 中，ryan 在 k1 中的 score 是100，在 k2 中的 score 是 80。</p></blockquote><ol><li><code>ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]</code>：交集<ul><li><code>ZINTERSTORE interkey 2 k1 k2 weights 1 0.5 AGGREGATE  SUM</code>：交集中 ryan 的 score是 100 * 1 + 80 * 0.5 = 150</li></ul></li><li><code>ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]</code>：并集</li></ol><h4 id="数值计算：-2"><a href="#数值计算：-2" class="headerlink" title="数值计算："></a>数值计算：</h4><ol><li><code>ZINCRBY key increment member</code></li></ol><h4 id="阻塞操作：-1"><a href="#阻塞操作：-1" class="headerlink" title="阻塞操作："></a>阻塞操作：</h4><ol><li><code>BZPOPMAX key [key ...] timeout</code></li><li><code>BZPOPMIN key [key ...] timeout</code></li></ol><h3 id="排序是怎么实现的，增删改查的速度如何"><a href="#排序是怎么实现的，增删改查的速度如何" class="headerlink" title="排序是怎么实现的，增删改查的速度如何"></a>排序是怎么实现的，增删改查的速度如何</h3><p>​    跳表实现，在数据量较大时候，相对于树结构（如红黑树），增删改查平均效率是最优的</p><h3 id="使用场景-5"><a href="#使用场景-5" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>基于排序特性，适合做排行榜，比如QQ音乐的乐曲热度排行榜</li></ul><p>​    </p><h2 id="通用类型命令"><a href="#通用类型命令" class="headerlink" title="通用类型命令"></a>通用类型命令</h2><ul><li><p><code>OBJECT subcommand [arguments [arguments ...]]</code></p><p>subcommand可以是以下命令：</p><ul><li><code>OBJECT encoding key</code>：查看key对应值的底层编码方式</li><li><code>OBJECT refcount key</code>：返回指定key对应值的被引用的次数，常用于调试</li><li><code>OBJECT idletime key</code>：返回指定key对应值自被存储之后空闲(没有读写操作的请求)的时间，单位为秒</li></ul></li><li><p><code>TYPE key</code>：查看键对应值的类型，这个类型信息存储在key中。如果一个命令不在指定key对应值类型所支持的命令范围内，会直接返回错误，而不是执行报错后返回，提升性能</p></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis/01-Redis介绍及NIO原理介绍</title>
      <link href="/2020/03/20/Redis/01-Redis%E4%BB%8B%E7%BB%8D%E5%8F%8ANIO%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/03/20/Redis/01-Redis%E4%BB%8B%E7%BB%8D%E5%8F%8ANIO%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis介绍及NIO原理介绍"><a href="#Redis介绍及NIO原理介绍" class="headerlink" title="Redis介绍及NIO原理介绍"></a>Redis介绍及NIO原理介绍</h1><h2 id="Redis缓存的由来"><a href="#Redis缓存的由来" class="headerlink" title="Redis缓存的由来"></a>Redis缓存的由来</h2><h3 id="一-数据存在硬盘上"><a href="#一-数据存在硬盘上" class="headerlink" title="一. 数据存在硬盘上"></a>一. 数据存在硬盘上</h3><p>​    起初，数据都在硬盘上，以文件形式进行存储和管理。当要获取特定数据时，可以通过linux命令<code>grep</code>，<code>awk</code>，或者写java程序来处理.</p><h4 id="痛点"><a href="#痛点" class="headerlink" title="痛点"></a>痛点</h4><p>​    随着文件变大，处理速度变慢了，为什么?因为硬盘I/O成为瓶颈，硬盘存取数据慢.</p><blockquote><p>常识:</p><p>带宽: 指的是设备在传输数据的时候数据流的速度</p><p>机械硬盘:</p><pre><code>1. 寻址: ms2. 带宽: x0MBps</code></pre><p>固态硬盘:</p><pre><code>1. 寻址: 由于不用磁头，寻址时间几乎为02. 带宽: x00MBps</code></pre><p>内存:</p><pre><code>1. 寻址: ns2. 带宽: GBps</code></pre><p>内存存取数据的速度是机械硬盘的10w倍，是固态硬盘的1k倍</p><p>硬盘的带宽比内存满了10倍</p></blockquote><blockquote><p>I/O buffer: 成本问题</p><p>磁盘有磁道和扇区，一扇区有512个Bytes.如果操作系统一次只读取512个Bytes，那么索引成本就会变大</p><p>实际情况是，无论你读多少数据，os都是直接默认读取4k的倍数，这样索引成本会减小.</p><p>格式化磁盘的时候，存在4k对齐事情，就是将文件系统格式与硬盘物理层上进行契合，为了提高硬盘寿命与高效使用硬盘空间</p></blockquote><h3 id="二-关系型数据库的出现"><a href="#二-关系型数据库的出现" class="headerlink" title="二. 关系型数据库的出现"></a>二. 关系型数据库的出现</h3><p>​    为了解决硬盘I/O瓶颈问题，数据库出现了.</p><ol><li><p>数据库里数据由多个data page组成，每个data page大小都是4k，可以和操作系统的4k对上.操作系统每次读数据就是读整数个data page数据.</p></li><li><p>每个data page里包含多条数据，通过主键可以快速在这4k里找到对应条目数据.</p></li><li><p>在关系型数据库中，schema(表规格，数据类型等)必须提前定义好，这时每行数据所需字节数已经固定了，当插入数据时，会进行<font color='green'>行级存储</font>（如果一行一共有10个字段，只有2个字段设了值，那么没设值的字段也会用字节把磁盘位置占住，当修改这条记录时，只需要覆盖对应位置磁盘数据，而不需要移动数据）.</p></li><li><p>如果只是把数据分成了data page，找数据时候还是一个4k一个4k的找，此时效率并没有提升，仍然走的是全量I/O.为此数据库提供了针对列的索引功能.索引也存储在data page里，同时在内存中会维护一个B+树，这个B+树所有树干是在内存中的，而叶子指向存了索引的data page. 当一个sql来了，通过where语句匹配到索引字段，B+树就把索引对应的data page读到内存，进行解析，找到对应数据行所在的data page，最后读取该数据data page，从而找到行数据.</p></li></ol><p>   简单来说，数据库将数据分成4k存储，与os的一次磁盘读取量一致，<font color='red'>性能的提升关键是增加索引来实现.</font></p><p>   ![关系型数据库data page与索引](.\pics\关系型数据库data page与索引.jpg)</p><h4 id="痛点-1"><a href="#痛点-1" class="headerlink" title="痛点"></a>痛点</h4><p>​    当数据库表很大时，性能会如何?假设表有索引的情况</p><ul><li>增删改会变慢</li><li>查询速度如何?<ul><li>1个或少量查询依然很快</li><li>并发大的时候，会受硬盘带宽限制影响速度.因为在进行大量查询时，要查询大量的data page，此时硬盘仍是瓶颈</li></ul></li></ul><h3 id="三-内存级别关系型数据库"><a href="#三-内存级别关系型数据库" class="headerlink" title="三. 内存级别关系型数据库"></a>三. 内存级别关系型数据库</h3><p>​    有一家公司叫SAP，量级和IBM类似，该公司发明了一种内存级别的关系型数据库HANA，这个数据库数据全部存在内存里，内存约是2TB，数据吞吐量高达100 GBps.</p><p>​    数据放在磁盘和数据放在内存中耗费的体积是不一样的，由于磁盘需要额外空间存储指针，存储索引等，一个数据存了多份，存在数据涨出，而内存里不需要存索引、指针，因此存在内存中耗费更少体积。</p><h4 id="痛点-2"><a href="#痛点-2" class="headerlink" title="痛点"></a>痛点</h4><p>​    性能上确实没问题了，但是运行数据库的服务器都是定制的，整台机器+数据库软件+服务的价格约是2亿，成本太高，普通公司用不起.</p><h3 id="四-缓存的出现"><a href="#四-缓存的出现" class="headerlink" title="四. 缓存的出现"></a>四. 缓存的出现</h3><p>​    用硬盘的关系型数据库在高并发下硬盘仍是瓶颈，而内存级关系型数据库太贵根本用不起，为了找到折中的方案，缓存的概念被提出了，将一部分数据从硬盘中迁到内存里做计算，这部分数据就叫缓存。</p><blockquote><p><a href="https://db-engines.com/en/" target="_blank" rel="noopener">数据库引擎排行网站</a>：一个很有价值、全面的数据库网站，可以看到各种数据库的最新排行和特点，适合数据库技术选项时候查阅。</p></blockquote><p><img src=".%5Cpics%5C%E5%8E%86%E5%8F%B2%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B.png" alt="历史技术演进"></p><h2 id="Redis基本介绍"><a href="#Redis基本介绍" class="headerlink" title="Redis基本介绍"></a>Redis基本介绍</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>​    Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 <a href="http://redis.cn/topics/data-types-intro.html#strings" target="_blank" rel="noopener">字符串（strings）</a>， <a href="http://redis.cn/topics/data-types-intro.html#hashes" target="_blank" rel="noopener">散列（hashes）</a>， <a href="http://redis.cn/topics/data-types-intro.html#lists" target="_blank" rel="noopener">列表（lists）</a>， <a href="http://redis.cn/topics/data-types-intro.html#sets" target="_blank" rel="noopener">集合（sets）</a>， <a href="http://redis.cn/topics/data-types-intro.html#sorted-sets" target="_blank" rel="noopener">有序集合（sorted sets）</a> 与范围查询， <a href="http://redis.cn/topics/data-types-intro.html#bitmaps" target="_blank" rel="noopener">bitmaps</a>， <a href="http://redis.cn/topics/data-types-intro.html#hyperloglogs" target="_blank" rel="noopener">hyperloglogs</a> 和 <a href="http://redis.cn/commands/geoadd.html" target="_blank" rel="noopener">地理空间（geospatial）</a> 索引半径查询。 Redis 内置了 <a href="http://redis.cn/topics/replication.html" target="_blank" rel="noopener">复制（replication）</a>，<a href="http://redis.cn/commands/eval.html" target="_blank" rel="noopener">LUA脚本（Lua scripting）</a>， <a href="http://redis.cn/topics/lru-cache.html" target="_blank" rel="noopener">LRU驱动事件（LRU eviction）</a>，<a href="http://redis.cn/topics/transactions.html" target="_blank" rel="noopener">事务（transactions）</a> 和不同级别的 <a href="http://redis.cn/topics/persistence.html" target="_blank" rel="noopener">磁盘持久化（persistence）</a>， 并通过 <a href="http://redis.cn/topics/sentinel.html" target="_blank" rel="noopener">Redis哨兵（Sentinel）</a>和自动 <a href="http://redis.cn/topics/cluster-tutorial.html" target="_blank" rel="noopener">分区（Cluster）</a>提供高可用性（high availability）。</p><blockquote><p><a href="https://redis.io" target="_blank" rel="noopener">英文官网</a>、<a href="http://redis.cn/" target="_blank" rel="noopener">中文官网</a></p></blockquote><h3 id="和memcached差异"><a href="#和memcached差异" class="headerlink" title="和memcached差异"></a>和memcached差异</h3><p>​    从Redis定义可以看出，Redis数据以key、value形式存储，其中value是分数据结构的。而在Redis之前已经存在了一个key、value型的内存数据库memcached，但是memcached的value是不区分类型的，这使我们自然而然想到了json。</p><ol><li>memcached的value可以存储json格式数据，json格式本身可以表现任何复杂的数据。</li><li>如果memcached存储的是json格式数据，数据可以很大很复杂，这就带来三个特点：<ol><li>客户端每次必须获取json的全量数据；</li><li>全量数据都是要走客户端、服务端网卡I/O的，当数据很大时容易成为瓶颈；</li><li>client在获取json数据后，需要有代码实现进行数据解析。</li></ol></li><li>Redis中值的类型并不重要，一个字符串类型就可以存储json格式数据来呈现复杂的数据结构。重要的是redis-server对每种类型提供了相应的方法，如<code>strlen</code>、<code>index</code>、<code>lpop</code>等。这体现了一种大数据中的重要思想：<font color='red'>计算向数据移动</font>。</li></ol><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><img src=".%5Cpics%5Credis%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4.jpg" alt="redis安装步骤"></p><p>​    三个知识点：</p><ol><li><font color='red'>下载完源码包后，要条件反射地看README！所有的编译、安装、服务化启动等操作步骤里面全有</font></li><li>第16步，配置redis以服务化形式运行，执行脚本后会在<code>/etc/init.d/</code>目录下生成一个redis_6379.server文件，作为redis_6379服务的执行脚本，当执行<code>service redis_6379</code>或者<code>systemctl</code>命令时就会执行该脚本</li><li>Redis可以装多个，在不同的端口上运行，服务名称为<code>redis_$PORT</code></li></ol><h2 id="linux内核的socket-I-O演进"><a href="#linux内核的socket-I-O演进" class="headerlink" title="linux内核的socket I/O演进"></a>linux内核的socket I/O演进</h2><p>​    众所周知Redis性能很高，号称单机15w并发。Redis性能高的原因与它的底层模型密不可分。Redis分客户端和服务端，那么一定会走以太网进行socket连接（socket是对TCP/IP的封装），socket的I/O将会是性能的关键。</p><p>​    在理解Redis模型之前，需要对linux内核中的socket I/O演进有了解。</p><h3 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h3><p>​    这是最初的socket模型，BIO全称是blocking I/O，同步阻塞I/O。</p><p><img src="./pics/BIO.jpg" alt="BIO"></p><blockquote><p>查看进程的所有文件描述符：</p><p>ps -ef |grep redis</p><p>ll /proc/$PID/fd/</p><p>![redis fds](./pics/redis fds.jpg)</p></blockquote><blockquote><p>在linux中，安装man命令及文档后，可以方便地看到很多帮助文档</p><p><code>yum install -y man man-pages</code></p><p><code>man 2 read</code>，查看man中2类关于read的文档。2类代表系统调用</p><p><img src="./pics/man%E6%96%87%E6%A1%A3%E7%B1%BB%E5%9E%8B.jpg" alt="man文档类型"></p></blockquote><h3 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h3><p><img src="./pics/NIO.jpg" alt="NIO"></p><p>关键点：<font color='red'>内核的socket支持了SOCK_NONBLOCK类型，使read调用可以不阻塞，实现同步非阻塞NIO</font></p><blockquote><p>man 2 socket</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DESCRIPTION</span><br><span class="line">       socket() creates an endpoint for communication and returns a descriptor.</span><br><span class="line">       ......</span><br><span class="line">       </span><br><span class="line">       Since  Linux  2.6.27， the type argument serves a second purpose: in addition to specifying a socket type， it may include the</span><br><span class="line">       bitwise OR of any of the following values， to modify the behavior of socket():</span><br><span class="line"></span><br><span class="line">       SOCK_NONBLOCK   Set the O_NONBLOCK file status flag on the new open file description.  Using this flag saves extra calls  to</span><br><span class="line">                       fcntl(2) to achieve the same result.</span><br></pre></td></tr></table></figure></blockquote><h3 id="多路复用的NIO"><a href="#多路复用的NIO" class="headerlink" title="多路复用的NIO"></a>多路复用的NIO</h3><p><img src="./pics/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8NIO.jpg" alt="多路复用NIO"></p><p>关键点：<font color='red'>内核提供了select调用，支持一次传递多个fds并交由内核轮询，实现多路复用NIO</font></p><blockquote><p>man 2 select</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DESCRIPTION</span><br><span class="line">       select()  and pselect() allow a program to monitor multiple file descriptors， waiting until one or more of the file descrip‐</span><br><span class="line">       tors become &quot;ready&quot; for some class of I&#x2F;O operation (e.g.， input possible).  A file descriptor is considered ready if it  is</span><br><span class="line">       possible to perform the corresponding I&#x2F;O operation (e.g.， read(2)) without blocking.</span><br></pre></td></tr></table></figure></blockquote><h3 id="共享空间的多路复用NIO"><a href="#共享空间的多路复用NIO" class="headerlink" title="共享空间的多路复用NIO"></a>共享空间的多路复用NIO</h3><p><img src="./pics/%E5%9F%BA%E4%BA%8Emmap%E7%9A%84%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8NIO.jpg" alt="基于mmap的多路复用NIO"></p><p>当调用<code>epoll_create</code>后，内核就会创建一个<code>eventpoll</code>结构</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">eventpoll</span>&#123;</span>  </span><br><span class="line">    ....  </span><br><span class="line">    <span class="comment">/*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/</span>  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">rb_root</span>  <span class="title">rbr</span>;</span>  </span><br><span class="line">    <span class="comment">/*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/</span>  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">rdlist</span>;</span>  </span><br><span class="line">    ....  </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>关键点：<font color='red'>内核提供了mmap调用，使内核态和用户态可以有一片共享空间。将fds放进共享空间，使两者都可见，无需将fds从两态间拷来拷去</font></p><blockquote><p>man 2 mmap</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DESCRIPTION</span><br><span class="line">       mmap()  creates a new mapping in the virtual address space of the calling process.  The starting address for the new mapping</span><br><span class="line">       is specified in addr.  The length argument specifies the length of the mapping.</span><br></pre></td></tr></table></figure></blockquote><blockquote><p>man epoll</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DESCRIPTION</span><br><span class="line">       The  epoll  API performs a similar task to poll(2): monitoring multiple file descriptors to see if I&#x2F;O is possible on any of</span><br><span class="line">       them.  The epoll API can be used either as an edge-triggered or a level-triggered interface and scales well to large numbers</span><br><span class="line">       of watched file descriptors.  The following system calls are provided to create and manage an epoll instance:</span><br><span class="line"></span><br><span class="line">       *  epoll_create(2)  creates  an  epoll  instance and returns a file descriptor referring to that instance.  (The more recent</span><br><span class="line">          epoll_create1(2) extends the functionality of epoll_create(2).)</span><br><span class="line"></span><br><span class="line">       *  Interest in particular file descriptors is then registered via epoll_ctl(2).  The set of file descriptors currently  reg‐</span><br><span class="line">          istered on an epoll instance is sometimes called an epoll set.</span><br><span class="line"></span><br><span class="line">       *  epoll_wait(2) waits for I&#x2F;O events， blocking the calling thread if no events are currently available.</span><br></pre></td></tr></table></figure><p>可以看出epoll具体包含三个调用</p><ol><li>epoll_crearte：创建一个epoll实例并返回引用该实例的文件描述符，该文件描述符用于对epoll接口的所有后续调用</li><li>epoll_ctl：对epoll实例进行操作的系统调用，包括<code>EPOLL_CTL_ADD</code>、<code>EPOLL_CTL_MOD</code>和<code>EPOLL_CTL_DEL</code></li><li>epoll_wait：等待I / O事件，如果当前没有可用的事件，则阻塞调用线程。方法返回就绪的fd个数，当出错时会返回-1</li></ol></blockquote><h3 id="未实现的AIO"><a href="#未实现的AIO" class="headerlink" title="未实现的AIO"></a>未实现的AIO</h3><p>​    演进到”更高效的多路复用NIO”为止，所有的I/O操作都还是同步的：线程自己调用read方法去读数据，读出数据后自己进行处理。那什么是异步IO呢？</p><p>​    异步I/O是一种异步回调机制，用户态线程告诉内核要读fd数据后，额外告诉内核一个回调/钩子函数，然后线程继续干其他的事。内核在发现fd中有数据可读后，调用传入的回调/钩子函数，来通知用户态线程已经有数据了，之后内核会继续干其他的事。</p><p>​    异步I/O也叫做AIO，目前windows系统是正真实现了AIO的，而linux系统没有实现AIO，因为linux系统为了安全和稳定，对用户态和内核态交互狠严格，因此实现AIO非常困难。IBM和Oracle都实现过linux的AIO，但是linus有代码洁癖，对他们的实现都不满意，所以并没有加入内核中。</p><h3 id="sendfile零拷贝"><a href="#sendfile零拷贝" class="headerlink" title="sendfile零拷贝"></a>sendfile零拷贝</h3><p>​    前面的内容不涉及零拷贝，零拷贝是另一个系统调用sendfile。</p><p><img src="./pics/sendfile.jpg" alt="sendfile"></p><blockquote><p>man 2 sendfile</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DESCRIPTION</span><br><span class="line">       sendfile()  copies data between one file descriptor and another.  Because this copying is done within the kernel， sendfile()</span><br><span class="line">       is more efficient than the combination of read(2) and write(2)， which would require  transferring  data  to  and  from  user space.</span><br><span class="line"></span><br><span class="line">       in_fd should be a file descriptor opened for reading and out_fd should be a descriptor opened for writing</span><br></pre></td></tr></table></figure></blockquote><h2 id="Redis底层架构"><a href="#Redis底层架构" class="headerlink" title="Redis底层架构"></a>Redis底层架构</h2><p><img src="./pics/Redis%E6%9E%B6%E6%9E%84.png" alt="Redis架构"></p><ol><li><p>epoll：redis底层通过epoll调用进行数据处理</p></li><li><p>跨主机8w并发：对于客户端和服务器不在一台主机上时，报文需要走两轮完整协议栈，一个服务端能处理8w左右的并发</p></li><li><p>单机15w并发：当客户端和服务端都在同一主机上时，无需走底层硬件，报文传递路径如下：</p><p>socket接口 -&gt; 传输层（tcp/udp报文） -&gt; 网络层 -&gt; back to 传输层 -&gt; backto socket接口</p><p>因此单机比跨主机性能更高，单机可支撑15w并发</p></li><li><p>单机多服务端：一台主机上可以有多个redis服务端，多个redis服务端之间用端口号区分</p></li><li><p>16个库：每个redis服务端自带16个库，名字分别是”0”、”1”…”15”，这个名字无法改变</p></li><li><p><font color='red'>一个工作线程</font>：每个redis服务端是一个进程，只有一个工作（worker）线程和其他的redis服务端线程。为什么只有一个worker？因为cpu不是redis的瓶颈，且单线程容易实现。redis的瓶颈最有可能是机器内存或网络带宽</p></li><li><p>顺序性：worker线程针对每个已到达连接内的指令按顺序执行</p></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>test</title>
      <link href="/2020/03/19/test/"/>
      <url>/2020/03/19/test/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> a </tag>
            
            <tag> b </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/03/19/hello-world/"/>
      <url>/2020/03/19/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
